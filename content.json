{"posts":[{"title":"Java 建立大顶堆","text":"Thought 从最后一个有孩子的父节点开始调整，若父节点的值小于左右孩子结点的值（如果有的话），就与该孩子结点交换位置。若发生了交换，由于原来父节点到了他的孩子结点上，可能破坏了现在这颗以原来父节点为根节点的子树，所以需要重复以上步骤，即递归。 数组的范围是从 0 ~ length - 1，设父节点的下标为 p，则： 12p的左孩子下标为：2 * p + 1p的右孩子下标为：2 *p + 2 最后一个有孩子的父节点下标为（length - 2）/ 2 Java Codes1234567891011121314151617181920212223242526272829303132333435363738public class BuildHeap { public void heapify(int[] heap, int item) { int length = heap.length; int left = 2 * item + 1; int right = 2 * item + 2; int largest; if (left &lt;= length - 1 &amp;&amp; heap[left] &gt; heap[item]) { largest = left; } else { largest = item; } if (right &lt;= length - 1 &amp;&amp; heap[right] &gt; heap[largest]) { largest = right; } if (largest != item) { // 父节点小于左右孩子结点,需要交换 int temp = heap[item]; heap[item] = heap[largest]; heap[largest] = temp; // 发生过交换后,原来父结点现在所在位置的值不一定还满足大顶堆的定义，需要递归继续建堆 heapify(heap, largest); } } public void build(int[] heap) { int length = heap.length; // 最后一个有孩子的结点的下标 int lastParent = (length - 2) / 2; for (int item = lastParent; item &gt;= 0; item--) { heapify(heap, item); } }} Test1234567891011public class Test { public static void main(String[] args) { BuildHeap buildHeap = new BuildHeap(); int[] heap = new int[] { 1, 2, 16, 14, 8, 7 }; buildHeap.build(heap); System.out.println(Arrays.toString(heap)); }}","link":"/2020/02/02/algo-build-heap/"},{"title":"Java 求最大子数组","text":"Background在某天购入股票后抛出，求如何取得最大利润。已知股票趋势如图所示。 Thought我们都知道——利润 = 售价 - 成本，即两者之差越大则利润越大。要求利润的最大值，不妨先计算出当天与前一天股价的差，得到的股价浮动数组，然后找其最大子数组，即为原问题的解。 对于最大子数组，最简单粗暴的方法就是两层 for，遍历所有子数组后，自然能求出最大子数组。 更好的解决办法是用分治策略。将原问题分解为两个子问题 left 和 right，设跨过两个子问题中点的数组为 cross，比较 left、right 和 cross 的最大值即为原问题的最优解。 Brute Force1234567891011121314151617181920212223242526272829303132333435public class MaxSubarray { private int[] variation; public MaxSubarray(int[] array) { variation = new int[array.length - 1]; for (int i = 0; i &lt; array.length - 1; ++i) { variation[i] = array[i + 1] - array[i]; } }// 暴力法 public void bruteForce() { int sum = 0; int start = 0; int end = 0; for (int i = 0; i &lt; variation.length; ++i) { int temp = 0; for (int j = i; j &lt; variation.length; ++j) { temp += variation[j]; if (temp &gt; sum) { sum = temp; start = i; end = j; } } } System.out.println(&quot;maxPrice： &quot; + sum + &quot;，index： [&quot; + start + &quot;, &quot; + end + &quot;]&quot;); }} Divide and Conquer Divide: Divide the array A[low..high] into two subarrays of n/2 elements, A[low..mid] and A[mid+1..high]. Conquer: Find the maximum subarray recursively. Combine: Select a subarray with the largest sum of the sub-problems’. 分：将数组从中间一分为二\\治：递归寻找最大子数组\\合并：选出子问题中和最大的子数组 Pseudo Code递归寻找数组中子数组的最大值 数组的最大值 = max{左子数组的最大值, 从中间向两边展开的数组的最大值, 右子数组的最大值} 寻找从中间位置向两边展开的数组的最大值 Example Java Codes1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class MaxSubarray { private int[] variation; public MaxSubarray(int[] array) { variation = new int[array.length - 1]; for (int i = 0; i &lt; array.length - 1; ++i) { variation[i] = array[i + 1] - array[i]; } } public int divideConquer() { return divideConquer(variation, 0, variation.length - 1); } private int divideConquer(int[] array, int left, int right) { if (left == right) { return array[left]; } else { int mid = (left + right) / 2; int left_sum = divideConquer(array, left, mid); int right_sum = divideConquer(array, mid + 1, right); int cross_sum = crossing(array, left, mid, right);// 比较三者最大值 return left_sum &gt; cross_sum ? (left_sum &gt; right_sum ? left_sum : right_sum) : (cross_sum &gt; right_sum ? cross_sum : right_sum); } }// 求cross private int crossing(int[] array, int left, int mid, int right) { int temp_left = -99999; int temp_right = -99999;// 从mid向前求最大值 int sum = 0; for (int i = mid; i &gt;= left; --i) { sum += array[i]; if (sum &gt; temp_left) { temp_left = sum; } }// 从mid+1向后求最大值 sum = 0; for (int j = mid + 1; j &lt; right; ++j) { sum += array[j]; if (sum &gt; temp_right) { temp_right = sum; } } return temp_left + temp_right; }} Test123456public static void main(String[] args) { int[] array = { 100, 113, 110, 85, 105, 102, 86, 63, 81, 101, 94, 106, 101, 79, 94, 90, 97 }; MaxSubarray maxSubarray = new MaxSubarray(array); maxSubarray.bruteForce(); System.out.println(&quot;分治：&quot; + maxSubarray.divideConquer());} Time Complexity 暴力法：$O(n^2)$ 分治法： 对于规模为 $n$ 的数组，除了递归搜索左、右子数组外，还需要求 cross（开销为 $O(n)$），以及比较三个值的大小（开销为 $O(1)$） 故：$T(n) = 2T(n/2) + O(n) + O(1)$ 根据算法时间复杂度的 master 方法，此时 $a = 2, b = 2, \\log_b{a} = 1$ 由于 $f(n) = n + 1 = \\Theta(n^{\\log_b{a}})$ （简单起见，假定$f(n) = O(n) + O(1) = n + 1$）, 满足 master 方法的 case 2, 故时间复杂度为： $T(n) = \\Theta(n^{\\log_b{a}}logn) = \\Theta(nlogn)$","link":"/2020/02/02/algo-max-subarray/"},{"title":"Java 分治策略实现快速排序","text":"Thought Divide: Partition the array into two subarrays around a pivot x such that elements in lower subarray ≤ x ≤ elements in upper subarray. Conquer: Recursively sort the subarrays. Combine: Trivial. 以枢轴 x 为中点，每次排序将小于枢轴 x 的元素都放在 x 左边，大于 x 的元素都放在 x 右边，然后递归以同样方式对子数组排序 Pseudo Code递归求解两个子序列 划分序列，返回枢轴 x Java Codes1234567891011121314151617181920212223242526272829303132333435363738394041424344public class QuickSort { public void quickSort(double[] array) { quickSort(array, 0, array.length - 1); } public void quickSort(double[] array, int left, int right) { if (left &lt; right) {// 枢轴 int pivot = partition(array, left, right); quickSort(array, left, pivot - 1); quickSort(array, pivot + 1, right); } } public int partition(double[] array, int left, int right) { int i = left; int j = right; while (i &lt; j) { while (i &lt; j &amp;&amp; array[i] &lt;= array[j]) { j--; } if (i &lt; j) { double temp = array[j]; array[j] = array[i]; array[i] = temp; i++; } while (i &lt; j &amp;&amp; array[i] &lt;= array[j]) { i++; } if (i &lt; j) { double temp = array[j]; array[j] = array[i]; array[i] = temp; } } return i; }} Test1234567891011121314151617181920212223public static void main(String[] args) {// 随机产生double数组 int length = 1000000; long start, end; double[] array = new double[length]; for (int i = 0; i &lt; length; i++) { double num = Math.random() * 10;// 将double值精确到小数点后两位 num = new BigDecimal(num).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); array[i] = num; } System.out.println(Arrays.toString(array));// 快速排序开始 start = System.currentTimeMillis(); // 获取开始时间 QuickSort quickSort = new QuickSort(); quickSort.quickSort(array); end = System.currentTimeMillis(); // 获取结束时间 System.out.println(&quot;快速排序运行时间： &quot; + (end - start) + &quot;ms&quot;); System.out.println(Arrays.toString(array));} Time Complexitybest-case快速排序最优的情况就是每一次取到的元素都刚好平分整个数组 此时的时间复杂度等式为：$T(n) = 2T(n/2) + O(n)$。$T(n/2)$ 为平分后的子数组的时间复杂度，$O(n)$ 为平分这个数组时所花的时间 根据算法时间复杂度的 master 方法，此时 $a = 2, b = 2, \\log_b{a} = 1$ 由于 $f(n) = n = \\Theta(n^{\\log_b{a}})$ （简单起见，假定$f(n) = O(n) = n$）, 满足 master 方法的 case 2, 故时间复杂度为： $T(n) = \\Theta(n^{\\log_b{a}}logn) = \\Theta(nlogn)$ 故最优情况下时间复杂度为：$O(nlogn)$ worst-case最差的情况就是每一次取到的元素刚好是数组中最小/最大的，这种情况就退化成冒泡排序了(每一次都选好一个元素的位置) 故最坏情况下时间复杂度为：$O(n^2)$ 可以通过随机选择枢轴来避免最坏情况的发生 average-case平均复杂度: $O(nlogn)$","link":"/2020/02/02/algo-quick-sort/"},{"title":"Java 分治策略实现归并排序","text":"Thought能不能使用分治策略的关键是 子问题的最优解是否可以通过某种手段得到原问题的最优解。对于归并排序，将两个已经有序的子问题序列进行合并，就可得到一个有序序列，以此类推，最终可将所有子问题序列合并成一个有序序列，而得到的有序序列就是最终答案。 图片来自简书，链接：https://www.cnblogs.com/chengxiao/p/6194356.html 至于如何合并，直接想到的就是开辟一个新空间，拿这两个子问题序列元素一一比对，将元素有序放到新空间里。 图片来自简书，链接：https://www.cnblogs.com/chengxiao/p/6194356.html Java Codes12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MergeSort { public MergeSort() { } public void mergeSort(double[] array) {// 开辟一个临时数组，避免在递归中频繁开辟空间 double[] result = new double[array.length]; mergeSort(array, 0, array.length - 1, result); } public void mergeSort(double[] array, int left, int right, double[] result) { if (left &lt; right) { int mid = (left + right) / 2; mergeSort(array, left, mid, result); mergeSort(array, mid + 1, right, result);// 将两个子问题序列合并 merge(array, left, mid, right, result); } } private void merge(double[] array, int left, int mid, int right, double[] result) { int i = left; int j = mid + 1; int k = 0; while (i &lt;= mid &amp;&amp; j &lt;= right) { if (array[i] &gt;= array[j]) { result[k++] = array[j++]; } else { result[k++] = array[i++]; } }// 将剩余的左子问题序列填充到result中 while (i &lt;= mid) { result[k++] = array[i++]; }// 将剩余的右子问题序列填充到result中 while (j &lt;= right) { result[k++] = array[j++]; }// 将result中元素填充到原序列中，以便继续排序 i = left; k = 0; while (i &lt;= right) { array[i++] = result[k++]; } }} Test1234567891011121314151617181920212223public static void main(String[] args) {// 随机产生double数组 int length = 1000000; long start, end; double[] array = new double[length]; for (int i = 0; i &lt; length; i++) { double num = Math.random() * 10;// 将double值精确到小数点后两位 num = new BigDecimal(num).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); array[i] = num; } System.out.println(Arrays.toString(array));// 归并排序开始 start = System.currentTimeMillis(); // 获取开始时间 MergeSort mergeSort = new MergeSort(); mergeSort.mergeSort(array); end = System.currentTimeMillis(); // 获取结束时间 System.out.println(&quot;归并排序运行时间： &quot; + (end - start) + &quot;ms&quot;); System.out.println(Arrays.toString(array));} Time Complexity归并排序的开销除了递归求解子问题外，还需要将子问题合并，开销为 $O(n)$ 故，归并排序的时间复杂度等式为：$T(n) = 2T(n/2) + O(n)$ 根据算法时间复杂度的 master 方法，此时 $a = 2, b = 2, \\log_b{a} = 1$ 由于 $f(n) = n = \\Theta(n^{\\log_b{a}})$ （简单起见，假定$f(n) = O(n) = n$）, 满足 master 方法的 case 2, 故时间复杂度为： $T(n) = \\Theta(n^{\\log_b{a}}logn) = \\Theta(nlogn)$ 归并排序无论在什么情况下都需要对每一个子问题进行排序，所以它的最好、最坏、平均情况的时间复杂度均为 $O(nlogn)$","link":"/2020/02/02/algo-merge-sort/"},{"title":"阿里云 CentOS 搭建 Hexo 详细教程","text":"本文将详细介绍如何在 CentOS 7 搭建 hexo 博客 1. 安装 Git这里使用压缩包的方式进行安装，尽管一键 yum install -y 更加简单粗暴，但是这样会把文件打散，使用压缩包的方式安装还能顺便学习许多命令和配置 安装依赖库和编译工具 1yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 下载 git 最新版本（tmp 目录用来存放临时文件，服务器重启后会自动清除） 1cd /tmp &amp;&amp; wget https://www.kernel.org/pub/software/scm/git/git-2.25.2.tar.gz 解压 1tar -zvxf git-2.25.2.tar.gz 编译 1cd git-2.25.2 &amp;&amp; make all prefix=/usr/local/git 安装 1make install prefix=/usr/local/git 配置环境变量 1echo 'export PATH=$PATH:/usr/local/git/bin' &gt;&gt; /etc/bashrc 使环境变量配置生效 1source /etc/bashrc 查看版本 1git version 配置用户名和邮箱 12git config --global user.name &quot;你的账号&quot;git config --global user.email &quot;你的邮箱&quot; 查看配置信息 1git config -l 生成 ssh 密钥 1ssh-keygen -t rsa -C &quot;你的 github 邮箱&quot; 打开 /root/.ssh/id_rsa.pub ，将其中内容添加到 GitHub 的 SSH Key 尝试使用 ssh clone 你的仓库 1git clone git@github.com:yourgithubid/repo.git 如果 clone 成功则说明 ssh 设置成功 2. 安装 Nodejs这里同样使用压缩包的方式进行安装 下载 nodejs 最新版本 1cd /tmp &amp;&amp; wget https://nodejs.org/dist/v12.16.0/node-v12.16.0-linux-x64.tar.xz 解压 1tar xvJf node-v12.16.0-linux-x64.tar.xz 将 /tmp/node-v12.16.0-linux-x64 文件夹移动到 /usr/local 目录下，并重命名为 node 1mv node-v12.16.0-linux-x64 /usr/local/node 添加软连接到 /bin 目录 123ln -s /usr/local/node/bin/node /bin/nodeln -s /usr/local/node/bin/npm /bin/npm 配置环境变量 1echo 'export PATH=/usr/local/node/bin:$PATH' &gt;&gt; /etc/profile 使环境变量配置生效 1source /etc/profile 查看 nodejs 和 npm 版本 123node -vnpm -v 如果正常显示，则安装成功 3. 安装 Hexo设置 npm 源为淘宝源 1npm config set registry https://registry.npm.taobao.org 安装 hexo 1npm install -g hexo-cli 查看版本 1hexo -v 4. 创建 Hexo 博客这里将博客放在 /data/blog 目录下 创建文件夹 1mkdir -p /data/blog &amp;&amp; cd /data/blog 初始化 hexo 1hexo init 生成 hexo 页面 1hexo g 此时会在目录下生成一个 public 文件，其中的 index.html 就是博客的主页面 5. 安装 Nginx这里同样使用压缩包的方式进行安装 安装依赖 1yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 同样在 /tmp 目录下，下载 nginx 最新版本 1cd /tmp &amp;&amp; wget http://nginx.org/download/nginx-1.16.1.tar.gz 解压 1tar -zxvf nginx-1.16.1.tar.gz 编译 1cd nginx-1.16.1 &amp;&amp; ./configure --with-http_ssl_module --with-http_ssl_module : 配置 ssl 模块 编译完后，会显示配置信息，默认将 nginx 安装到 /usr/local/nginx 安装 1make &amp;&amp; make install nginx 的配置文件在 /usr/local/nginx/conf 目录下，编辑 nginx.conf，按 i 进入 INSERT 模式 1234567vi /usr/local/nginx/conf/nginx.conf# 保存并退出:wq# 退出但不保存:q! 需在配置文件中修改监听的 server_name 为你的域名，以及 ssl 证书的目录和博客的目录 12345678910111213141516171819202122server { listen 443 ssl; # 修改域名或ip server_name blog.tsund.cn; # 修改ssl证书目录 ssl_certificate /data/ssl/blog_tsund_cn/chain.crt; ssl_certificate_key /data/ssl/blog_tsund_cn/key.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_prefer_server_ciphers on; # 修改博客目录 location / { root /data/blog/public; index index.html index.htm; } } 重启 nginx 123456789cd /usr/local/nginx/sbin./nginx -s reload# 启动 nginx./nginx# 关闭 nginx./nginx -s stop 访问博客地址，出现 hexo 界面 接下来，就可以将 GitHub 的博客迁移到服务器了","link":"/2020/02/18/blog-hexo/"},{"title":"Cloudflare Workers 实现301网址跳转","text":"本文将介绍如何基于 Cloudflare Workers 使用 Node.js 实现一个网址跳转服务，并自定义域名 Cloudflare Workers 在边缘运行代码，提供强大的 Web 可扩展性 在边缘应用 自定义安全规则 和 过滤逻辑 来检测恶意 Bots 病毒并防止它们消耗资源，从而提高安全性。 将更多个性化和交互性纳入静态 HTML 页面，并在边缘运行动态请求，从而改善用户体验。 将更多操作流程和请求处理转移到边缘，以提高缓存命中率并降低带宽成本，从而降低运营成本。 Cloudflare Workers 可以通过自定义安全规则和过滤逻辑来提高网站的安全性，因此，我们可以通过 t.domain1.com\\blog 301重定向到真实地址，如：blog.domain2.com，达到隐藏真实地址的目的 步骤1. 创建 Workers 点击创建 Worker 代码的主要思想是：对于诸如 to.domain1.com\\/blog 这样的请求，截取 / 后面的内容并查询 redirectMap，然后 301 跳转到相应网址，如 blog.domain2.com 代码如下，只需要根据需求自己修改 redirectMap 的内容就行了 12345678910111213141516async function handleRequest(request) { let requestURL = new URL(request.url) let path = requestURL.pathname.split('/')[1] let location = redirectMap[path] if (location) { return Response.redirect(location, 301) } return fetch(request)}addEventListener('fetch', async event =&gt; { event.respondWith(handleRequest(event.request))})const redirectMap = { blog: 'https://blog.tsund.cn/'} 2. 自定义域名注意：要使用的域名必须是由 Cloudflare 管理的 进入 Cloudflare 的域名界面后，点击 Workers 标签，并添加一条 route 然后是配置 route，可以使用通配符 注意：如果是二级域名，需要先给这个二级域名添加一条 CNAME 记录，否则跳转会有问题。Workers 会在 CNAME 之前拦截请求，只有未被拦截的才会走 CNAME 记录的地址。 所以这个根据自己需求就可以了 至此，就实现了通过 Cloudflare Workers 实现 301 网址跳转，达到隐藏目标网址的目的 如：https://t.shenke.codes/blog 会跳转到 https:\\/\\/blog.tsund.cn 更新：如果 CNAME 记录指向的是 GitHub Pages 的页面，可能出现 404 错误，尽管仓库中已经定义好 404 页面，但是依然还是显示默认的 404 页面，影响浏览体验。这时可以通过修改 Workers 代码让所有的请求就都经 Cloudflare Workers 处理，但是 CNAME 记录依然不可以删掉（好像是该条 DNS 记录必须存在 😛）。修改后的代码如下： 123456789101112131415161718async function handleRequest(request) { let requestURL = new URL(request.url) let path = requestURL.pathname.split('/')[1] let location = redirectMap[path] if (location) { return Response.redirect(location, 301) } else { return Response.redirect('https://tsund.cn/404/', 301) }}addEventListener('fetch', async event =&gt; { event.respondWith(handleRequest(event.request))})const redirectMap = { '': 'https://tsund.cn/', 'blog': 'https://blog.tsund.cn/'} 这样，访问 https://t.shenke.codes 就会跳转到 https:\\/\\/tsund.cn，并且对于 redirectMap 中尚未定义的跳转规则，会跳转到自定义的 404 页面，从而提高用户浏览体验","link":"/2020/02/02/cf-workers-redirect/"},{"title":"记录整数反转的溢出问题","text":"Leetcode simple problem: Reverse Integer给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。注意：假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [Integer.MIN_VALUE, Integer.MAX_VALUE]。请根据这个假设，如果反转后整数溢出那么就返回 0 Thought 先不考虑溢出问题，对整数取反很简单，先把 x 不断对 10 取余，然后 result 乘 10 加上余数覆盖掉原来的 result，最后 x /= 10 对于溢出问题，就需要判断最终得到的 result 的范围是否合法，而问题是如果 result 已经溢出，那么 result 就不能是 int 类型，要扩充一下的它的存储空间，让它表示比 int 还要大的数，那么它的类型就必须是 long（我没想到这点，提交了三遍都不对，最后看了评论才悟出来…） 另外，官方给出的答案有点复杂的味道： 图片来自 Leetcode 官方答案，链接：https://leetcode-cn.com/problems/reverse-integer/solution/zheng-shu-fan-zhuan-by-leetcode/ 其实个人感觉才是最稳妥最万能的做法，因为如果按刚才的做法，用一个 long 类型来保存结果，那如果题目改成是对 long 类型的数进行取反呢，再去用 long long 类型保存结果吗，但是对于这个题目来说这确实是最巧妙的解法了 Java Codes12345678910111213public int reverse(int x) { // 用long类型判断溢出 long result = 0; while (x != 0) { result = result * 10 + x % 10; x /= 10; } return (int) ((result &gt;= Integer.MIN_VALUE &amp;&amp; result &lt;= Integer.MAX_VALUE) ? result : 0);} Notes Integer.MIN_VALUE(-2^31)： -2147483648\\Integer.MAX_VALUE(2^31-1)： 2147483647 函数 Math.pow(a, b)，返回的是 a 的 b 次方，类型是 Double\\a ^ b 得到的也是 a 的 b 次方，但是返回的是 Integer 类型","link":"/2020/02/02/algo-reverse-integer/"},{"title":"通过 Docker 搭建 Chevereto 图床","text":"Chevereto 是一套基于 PHP 构建，易于安装和配置使用的开源在线图片存储分享服务系统 结合上篇 通过 Docker 搭建 Typecho 详细教程，通过 Docker Compose 编排 Mysql、PHP、Nginx 容器，同时部署 Typecho 和 Chevereto 1. 构建 PHP 镜像Dockerfile 内容如下所示： 123456789101112FROM php:7.2.3-fpmLABEL maintainer=&quot;tsund&quot; \\ email=&quot;tsund@qq.com&quot; \\ version=&quot;7.2.3-fpm&quot;RUN apt-get update \\ &amp;&amp; apt-get install -y libgd-dev libzip-dev \\ &amp;&amp; apt-get clean &amp;&amp; rm -rf /tmp/* &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; docker-php-ext-configure gd --with-freetype-dir=/usr/include/ --with-jpeg-dir=/usr/include/ --with-png-dir=/usr/include \\ &amp;&amp; docker-php-ext-install gd pdo pdo_mysql mysqli zipCOPY ./php.ini /usr/local/etc/php/conf.d/ 可通过以上 Dockerfile 自行构建，构建方法如下。亦可直接使用我构建好的镜像 tsund/php:7.2.3-fpm 下载 GitHub 仓库 中的 7.2.3-fpm 文件夹，cd 到该文件夹下，执行以下命令构建镜像 1docker build username/repo:tag . push 到 Docker Hub 1docker push username/repo:tag 2. 配置目录结构如下： 12345678910[root@shenke web]# tree -L 1.├── docker-compose.yml├── html├── mysql├── mysql.env├── nginx└── ssl4 directories, 2 files 2.1 配置 Nginx编写图床页面的配置文件，内容如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960server { listen 443 ssl; server_name img.tsund.cn; root /var/www/html/chevereto; index index.php; access_log /var/log/nginx/typecho_access.log main; ssl_certificate /var/www/ssl/img_tsund_cn.crt; ssl_certificate_key /var/www/ssl/img_tsund_cn.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location ~ .*\\.php(\\/.*)*$ { fastcgi_pass php:9000; fastcgi_index index.php; # fastcgi_connect_timeout 60s; # fastcgi_send_timeout 60s; # fastcgi_read_timeout 60s; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } # Chevereto NGINX generated rules for https://img.tsund.cn/ # Context limits client_max_body_size 20M; # Disable access to sensitive files location ~* /(app|content|lib)/.*\\.(po|php|lock|sql)$ { deny all; } # Image not found replacement location ~ \\.(jpe?g|png|gif|webp)$ { log_not_found off; error_page 404 /content/images/system/default/404.gif; } # CORS header (avoids font rendering issues) location ~* /.*\\.(ttf|ttc|otf|eot|woff|woff2|font.css|css|js)$ { add_header Access-Control-Allow-Origin &quot;*&quot;; } # Pretty URLs location / { index index.php; try_files $uri $uri/ /index.php$is_args$query_string; } # END Chevereto NGINX rules} 2.2 编写 docker-compose.yml内容参考如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152version: &quot;3&quot;services: nginx: image: nginx container_name: nginx ports: - &quot;80:80&quot; - &quot;443:443&quot; restart: always volumes: - ./html:/var/www/html - ./ssl:/var/www/ssl - ./nginx/conf.d:/etc/nginx/conf.d - ./nginx/nginx.conf:/etc/nginx/nginx.conf depends_on: - php networks: - web php: image: tsund/php:7.2.3-fpm container_name: php restart: always ports: - &quot;9000:9000&quot; volumes: - ./html:/var/www/html environment: - TZ=Asia/Shanghai depends_on: - mysql networks: - web mysql: image: mysql:5.7 container_name: mysql restart: always ports: - &quot;3306:3306&quot; volumes: - ./mysql/data:/var/lib/mysql - ./mysql/logs:/var/log/mysql - ./mysql/conf:/etc/mysql/conf.d env_file: - mysql.env networks: - webnetworks: web: 以上内容详解可参考 通过 Docker 搭建 Typecho 详细教程 3. 启动容器在存放目录下，执行以下命令启动容器 1docker-compose up -d 之后，浏览器进入图床页面开始配置即可","link":"/2020/09/16/docker-chevereto/"},{"title":"Docker 入门及常用命令","text":"1. Docker 基础知识 Build, Ship and Run Any App, Anywhere. Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口 Docker 的三个重要概念： Image（镜像） Container（容器） Repository（仓库） 其中，Image 是 Docker 的核心，它可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变 Container，顾名思义，它就是一个容器，其中装的就是 Image 镜像，它与 Image 的关系就好比是面向对象中的实例和类，Image 是静态的定义，Container 是 Image 运行时的实例。Image 说白了只是一个文件系统，而装载 Image 的 Container 可以被创建、启动、停止、删除、暂停等 Repository 是一个代码控制中心，用来保存镜像。每个仓库可以包含多个 Tag（标签），每个 Tag 对应一个镜像。通常，一个 Repository 会包含同一个软件不同版本的 Image，而 Tag 就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的 Image。如果不给出 Tag，将以 latest 作为默认标签 2. Docker 基本命令2.1 容器管理 docker run ：通过镜像创建一个新的容器并运行一个命令 1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 常用 OPTIONS： -d ：后台运行 Container -i ：以交互模式运行 Container，通常与 -t 同时使用 -t ：为 Container 重新分配一个伪输入终端，通常与 -i 同时使用（即 -it） -p ：指定 Container 与主机的端口映射，格式为：主机(宿主)端口:容器端口 --name=&quot;container-name&quot;: 为容器指定一个名称 docker start ：启动一个或多个已经被停止的容器 1docker start CONTAINER docker stop ：停止一个运行中的容器 1docker stop CONTAINER docker restart ：重启一个运行中的容器 1docker restart CONTAINER docker rm ：删除一个或多个容器 常用 OPTIONS： -f ：强制删除 Container 删除所有已停止的 Container 1docker rm $(docker ps -a -q) docker exec ：在指定运行的容器中执行操作，exit 后容器不会停止运行 1docker exec [OPTIONS] CONTAINER COMMAND [ARG...] 常用 -it 进入容器并执行命令（在伪终端中输入 exit 退出） 1docker exec -it CONTAINER /bin/bash 2.2 容器操作 docker ps ：查看正在运行的容器 常用 OPTIONS： -a ：列出所有 Container，包括未运行的 -q ：只列出 Container ID -s ：显示总的文件大小 docker inspect ：获取指定容器/镜像的元数据，返回内容格式默认为 json 1docker inspect CONTAINER docker port ：列出指定容器的端口映射 1docker port CONTAINER docker top ：查看指定运行容器中的进程信息，支持 ps 命令参数 1docker top [OPTIONS] CONTAINER [ps OPTIONS] 2.3 镜像管理 docker images ：列出本地镜像 常用 OPTIONS： -a ：列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层） -q ：列出本地镜像 ID docker rmi ：删除本地一个或多个镜像 1docker rmi [OPTIONS] IMAGE [IMAGE...] 常用 OPTIONS： -f ：强制删除 Image docker tag ：标记本地镜像，将其归入某一仓库 1docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] docker build ：使用 Dockerfile 创建镜像 1docker build [OPTIONS] PATH | URL | - 常用 OPTIONS： -t ：镜像的名字及标签，通常 name:tag 或者 name 格式，可以在一次构建中为一个镜像设置多个标签 -f ：指定要使用的 Dockerfile 路径 2.4 仓库操作 docker pull ：从镜像仓库中拉取或者更新指定镜像 1docker pull ubuntu docker search ：从 Docker Hub 中查找镜像 1docker search [OPTIONS] TERM 常用 OPTIONS： --automated ：只列出 automated build类型的镜像 --no-trunc ：显示完整的镜像描述 -s ：列出 star 数不小于指定值的镜像","link":"/2020/02/21/docker-introduce/"},{"title":"Nginx 的 Docker 镜像使用教程","text":"官方镜像说明用户可以将宿主主机上的网页文件、config 文件挂载到官方镜像中 官方镜像中 nginx 的安装目录为：/etc/nginx，配置文件目录为：/etc/nginx/config.d/default.conf，网页文件目录为：/usr/share/nginx/html 可以通过下面命令进入容器查看 1docker exec -it CONTAINER /bin/bash 官方镜像地址：https://hub.docker.com/_/nginx 使用教程 拉取镜像 1docker pull nginx 运行容器，这里将 /data/web 挂载到容器中的 /usr/share/nginx/html 1docker run -d --name nginx -p 80:80 -p 443:443 -v /data/web:/usr/share/nginx/html nginx 其中，各参数含义如下： -d: 表示使容器在后台运行--name: 指定容器名称-p: 指定容器与宿主主机的端口映射，格式为：宿主主机端口:容器端口-v: 指定容器与宿主主机的文件挂载，格式为：宿主主机目录:容器目录 将容器中的 nginx 目录拷贝到 /usr/local/ 目录下 1docker cp nginx:/etc/nginx /usr/local/ 停止并删除容器 123docker stop nginxdocker rm nginx 注意：以上步骤必须执行，因为容器的运行依赖 /etc/nginx，如果将一个空文件目录挂载到该目录，容器将无法启动，所以需要先将该文件目录拷贝到主机中，再挂载上去 重新运行一个新容器，这里将 /usr/local/nginx 挂载到容器中的 /etc/nginx 1docker run -d --name nginx -p 80:80 -p 443:443 -v /usr/local/nginx:/etc/nginx -v /data/web:/usr/share/nginx/html nginx 编辑配置文件 在宿主主机中，编辑 /usr/local/nginx/config.d/default.conf，修改网页文件路径，例如网页文件存放在宿主主机中的 /data/web/homepage，主页为 /data/web/homepage/index.html，由于将 /data/web 挂载到了 /usr/share/nginx/html，故配置文件中应该写为 1234location / { root /usr/share/nginx/html/homepage; index index.html index.htm;} HTTPS 配置 在 /usr/local/nginx/config.d/default.conf 中追加以下内容： 12345678910111213141516171819server { listen 443 ssl http2; server_name tsund.me; ssl on; ssl_certificate /usr/share/nginx/html/ssl/tsund_me/tsund.pem; ssl_certificate_key /usr/share/nginx/html/ssl/tsund_me/tsund.key; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { root /usr/share/nginx/html/homepage; index index.html index.htm; }} 其中，server_name 为域名，ssl_certificate 为 ssl 证书的路径，ssl_certificate_key 为 ssl 证书私钥的路径 重启容器 配置完后，需要重启容器 1docker restart nginx 至此，打开 https://your-domain.com 就可以看到网页内容了","link":"/2020/07/21/docker-nginx/"},{"title":"通过 Docker 搭建 Typecho 详细教程","text":"下面以 Centos 7 为例 1. 安装 Docker 和 Docker Compose1.1 安装 Docker安装依赖 1yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看所有仓库中所有docker版本 1yum list docker-ce --showduplicates | sort -r 安装docker 1yum install -y docker-ce 设置开机启动 1systemctl enable docker 启动 Docker 1systemctl start docker 查看版本 1docker version 测试 1docker pull ubuntu 1.2 安装 Docker Compose下载 1curl -L https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m) &gt; /usr/bin/docker-compose 赋予执行权限 1chmod +x /usr/bin/docker-compose 查看版本 1docker-compose --version 2. 构建镜像这里使用如下三个镜像 nginx tsund/php:7.2.3-fpm mysql:5.7 其中 nginx 为官方最新镜像，mysql:5.7 为官方 5.7 镜像，tsund/php:7.2.3-fpm 的 Dockerfile 如下： 12345678FROM php:7.2.3-fpmLABEL maintainer=&quot;tsund&quot; \\ email=&quot;tsund@qq.com&quot; \\ version=&quot;7.2.3&quot;RUN apt-get update \\ &amp;&amp; docker-php-ext-install pdo_mysql \\ &amp;&amp; echo &quot;output_buffering = 4096&quot; &gt; /usr/local/etc/php/conf.d/php.ini 在官方镜像的基础上，添加了 PDO_MYSQL（如果使用 MySQL 作为 Typecho 的数据库，则需安装此扩展），并设置 buffer 为 4kb，即一个内存页 3. 配置新建 blog 文件夹，其目录结构如下： 1234567.├── docker-compose.yml Docker Compose 配置文件├── mysql mysql 持久化目录├── mysql.env mysql 配置信息├── nginx nginx 配置文件的持久化目录├── ssl ssl 证书目录└── typecho 站点根目录 3.1 配置 docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: &quot;3&quot;services: nginx: image: nginx ports: - &quot;80:80&quot; - &quot;443:443&quot; restart: always volumes: - ./typecho:/var/www/html - ./ssl:/var/www/ssl - ./nginx:/etc/nginx/conf.d depends_on: - php networks: - web php: image: tsund/php:7.2.3-fpm restart: always ports: - &quot;9000:9000&quot; volumes: - ./typecho:/var/www/html environment: - TZ=Asia/Shanghai depends_on: - mysql networks: - web mysql: image: mysql:5.7 restart: always ports: - &quot;3306:3306&quot; volumes: - ./mysql/data:/var/lib/mysql - ./mysql/logs:/var/log/mysql - ./mysql/conf:/etc/mysql/conf.d env_file: - mysql.env networks: - webnetworks: web: 其中 version 指定 docker-compose 版本 image 指定镜像名称 volumes 指定文件挂载映射 ports 指定端口映射 depends_on 指定服务启动时的先后顺序，指定的服务会先于当前服务启动 networks 指定容器连接的虚拟网络，连接在同一网络的服务可以使用服务名进行通信。version 3 不推荐使用 --link，使用 network 替代其功能，也更方便管理 一级标签的 networks 是虚拟网络的定义，可以指定网络类型和参数等，这里使用了默认的网络类型，参数部分留空即可 3.2 配置 nginx在 ./nginx 目录下新建 default.conf 文件，参考内容如下： 1234567891011121314151617181920212223242526272829303132333435363738server { listen 80; server_name tsund.cn; rewrite ^(.*) https://tsund.cn$1 permanent;}server { listen 443 ssl http2 reuseport; server_name tsund.cn; root /var/www/html; index index.php; access_log /var/log/nginx/typecho_access.log main; ssl_certificate /var/www/ssl/tsund_cn.crt; ssl_certificate_key /var/www/ssl/tsund_cn.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; if (!-e $request_filename) { rewrite ^(.*)$ /index.php$1 last; } location ~ .*\\.php(\\/.*)*$ { fastcgi_pass php:9000; fastcgi_index index.php; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } 3.3 配置 mysqlmysql.env 参考内容如下： 12345678910# MySQL的root用户默认密码，这里自行更改MYSQL_ROOT_PASSWORD=password# MySQL镜像创建时自动创建的数据库名称MYSQL_DATABASE=blog# MySQL镜像创建时自动创建的用户名MYSQL_USER=shenke# MySQL镜像创建时自动创建的用户密码MYSQL_PASSWORD=password# 时区TZ=Asia/Shanghai 4. 安装4.1 编排容器在 blog 目录下 1docker-compose up -d 查看进程 1docker-compose ps 4.2 安装 Typecho编排成功后，浏览器输入 URL，进入 typecho 安装页面 需注意的是，数据库地址需填入 mysql 镜像的名称（与 docker-compose.yml 中的配置相对应），数据库名与 mysql.env 中创建的数据库名一致 若出现以上页面，只需按照提示在 ./typecho 目录下新建 config.inc.php 文件，并写入内容即可 5. 博客迁移迁移时只需将整个 blog 目录打包传输至安装有 Docker 和 Docker Compose 的新服务器，然后重新编排容器即可 1docker-compose up -d 6. 参考资料 使用 Docker 搭建 Typecho 个人博客 Docker安装typecho 使用Docker搭建Caddy+Typecho个人博客网站","link":"/2020/08/29/docker-typecho/"},{"title":"frp 远程连接内网主机详细教程","text":"1. 准备工作 一台有公网 ip 的 server 一台内网主机或路由器 2. 服务端配置（远程 server）这里以阿里云 Centos 7 为例 2.1 下载与安装进入 /tmp 目录 1cd /tmp 在 Releases 页面下载与 server 系统、架构相符的 frp 版本 1wget https://github.com/fatedier/frp/releases/download/v0.33.0/frp_0.33.0_linux_amd64.tar.gz 解压 1tar -zxvf frp_0.33.0_linux_amd64.tar.gz 移动到 /usr/local 目录下，并重命名为 frp 1mv frp_0.33.0_linux_amd64 /usr/local/frp 2.2 配置进入安装目录 /usr/local/frp，并删除客户端相关文件 1cd /usr/local/frp &amp;&amp; rm -rf frpc* 编辑配置文件 1vi frps.ini 写入以下内容： 123456[common]bind_port = 7000privilege_token = 123456dashboard_port = 7500dashboard_user = admindashboard_pwd = admin 其中，bind_port 为客户端与服务端进行通信的端口；privilege_token 为特权模式密钥，需与客户端配置一致；dashboard_port 为可视化面板的端口号；dashboard_user 为登录面板的用户名；dashboard_pwd 为登录密码 privilege_token 参数的作用是提供身份验证机制，避免其他客户端随意连接服务端 2.3 设置开机启动和后台运行新建文件 1vi /etc/systemd/system/frps.service 写入以下内容 12345678910111213[Unit]Description=frps daemonAfter=syslog.target network.targetWants=network.target[Service]Type=simpleExecStart=/usr/local/frp/frps -c /usr/local/frp/frps.iniRestart=alwaysRestartSec=1min[Install]WantedBy=multi-user.target 注意修改第 8 行的路径 设置开机启动 1systemctl enable frps 启动 frps 1systemctl start frps 3. 客户端配置（本地主机）这里以 win10 为例 3.1 下载与安装在 Releases 页面下载 windows_amd64 版本，并解压 删除 frps、frps.ini、frps_full.ini 3.2 配置编辑 frpc.ini 文件，写入以下内容： 12345678910[common]server_addr = tsund.meserver_port = 7000privilege_token = 123456[rdp]type = tcplocal_ip = 0.0.0.0local_port = 3389remote_port = 3389 其中，server_addr 为 server ip 地址或解析到该 ip 的域名，server_port 需与服务端 bind_port 保持一致，privilege_token 需与服务端 privilege_token 保持一致，下面的 rdp 标签设定了远程桌面连接的端口映射 3.3 设置开机启动在 frp 目录下新建文件 frp.vbs，并写入以下内容： 123dim objShell set objShell=wscript.createObject(&quot;WScript.Shell&quot;) iReturnCode=objShell.Run(&quot;D:\\frp\\frpc.exe -c D:\\frp\\frpc.ini&quot;, 0, TRUE) 注意修改第 3 行的路径 将 frp.vbs 放入 C:\\Users\\shenke\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup 目录下，即可实现开机启动 双击运行 frp.vbs ，即可启动 frpc 服务 3.4 允许远程桌面连接「右键此电脑」-&gt;「属性」-&gt;「高级系统设置」-&gt;「远程」-&gt;「允许远程连接到此计算机」 4. 客户端配置（路由器）这里以 Padavan 固件的 PHICOMM K2 路由器为例。Padavan 固件内置了 frps 和 frpc，这里以 frpc 为例 绑定本地主机的 ip 地址和 mac 地址 「高级设置」-&gt;「内部网络（LAN）」-&gt;「DHCP 服务器」-&gt;「手动指定 IP 的 DHCP 列表」 配置 frpc 「扩展功能」-&gt;「花生壳内网版」-&gt;「frp」 配置方法同 3.2，只需修改 local_ip 为 DHCP 服务器分配给本地主机的 ip 5. 测试访问 http://your-ip:7500，进入 frp 的 dashboard 页面，如果无法访问，说明 frp 尚未启动成功或者 server 的端口未成功开放 查看 frp 进程是否运行 1top 如果 frp 进程没有运行，可能是因为 frp 版本与 server 的操作系统或架构不符，再次下载相符的版本重新配置即可 查看 server 端口占用情况 12345# linuxnetstat -nltp# windowsnetstat -an 通过站长工具的 端口扫描 查看 server 端口是否对外开放 如果 server 中端口开放，但是端口扫描显示关闭，只需去控制台配置安全组即可 6. 连接这里以 win10 电脑为例，远程连接内网中的 win10 主机 win + r，输入 mstsc，进入远程桌面连接 输入计算机：ip:port 或 domain:port，根据前面的配置，我这里输入的是 tsund.me:3389 用户名和密码填写的是内网主机的用户名和密码（内网主机中我登录的是 MicroSoft 账户，开机密码是六位 PIN 码，但是输入了电脑用户名和 MicroSoft 账户密码才进去的）","link":"/2020/07/24/frp-remote-desktop/"},{"title":"Docker 入门之 Dockerfile","text":"1. Dockerfile通常使用 Dockerfile 创建镜像，Dockerfile是一个 Docker 镜像的描述文件，其内部包含了一条条的指令，每一条指令构建一层，每一条指令的内容，就是描述该层应当如何构建。每条指令按顺序依次执行 2. 指令详解2.1 FROM指定基础镜像，并且必须是 Dockerfile 的第一条指令，如果不以任何镜像为基础，那么写法为：FROM scratch 12345678FROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;:&lt;digest&gt;# 例如FROM scratchFROM centos:6FROM ubuntu 2.2 MAINTAINER指定作者信息 1234MAINTAINER &lt;name&gt;# 例如MAINTAINER shenke &lt;shenkebug@gmail.com&gt; 注：新版 docker 建议使用 LABEL 声明 2.3 LABEL为镜像指定标签 12345678LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ···# 例如# 内容过长可用 \\ 换行LABEL maintainer=&quot;shenke&quot; \\version=&quot;1.0&quot; \\desc=&quot;This is \\a short description.&quot; 2.4 RUN构建镜像时执行的 Shell 命令 1234567RUN &lt;command&gt;RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]# 例如RUN sh run.shRUN [&quot;sh&quot;, &quot;run.sh&quot;]RUN [&quot;yum&quot;, &quot;install&quot;, &quot;nginx&quot;] 2.5 CMD启动容器时执行的 Shell 命令 12345678CMD command param1 param2CMD [&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]# 例如CMD echo $HOMECMD [&quot;sh&quot;, &quot;run.sh&quot;]CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;] RUN 与 CMD 的区别： RUN 指定的是构建镜像时要执行的命令，即 docker build 过程中要执行的命令 CMD 指定的是启动容器时要执行的命令，即 docker run 时要执行的命令。CMD 指令的首要目的在于为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。注意：CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖 2.6 ENTRYPOINT启动容器时执行的 Shell 命令 12ENTRYPOINT command param1 param2ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT 与 CMD 的异同： 都是在启动容器时执行 ENTRYPOINT 启动的程序不会被 docker run 命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给 ENTRYPOINT 指令指定的程序 2.7 EXPOSE暴露容器端口给外部 1234EXPOSE &lt;port&gt;/&lt;tcp/udp&gt;# 例如EXPOSE 80/tcp 443/tcp 2.8 ADD将主机文件或目录拷贝到镜像中，URL 会自动下载，压缩包会自动解压 123456ADD &lt;src&gt; ··· &lt;dest&gt;ADD [&quot;&lt;src&gt;&quot;, ··· &quot;&lt;dest&gt;&quot;]# 例如ADD nginx-1.16.1.tar.gz /usr/local # 将 nginx 压缩包解压到 /usr/local 目录下，即 /usr/local/nginx-1.16.1ADD https://xxx.com/html.tar.gz /var/www/html # 下载压缩包并解压到 /var/www/html 目录下 注意： src 为一个目录的时候，会自动把目录下的文件复制过去，目录本身不会复制 如果 src 为多个文件，dest 必须是一个目录 2.9 COPY将主机文件或目录拷贝到镜像中，同 ADD 类似，只是不支持自动下载和解压 12ADD &lt;src&gt; ··· &lt;dest&gt;ADD [&quot;&lt;src&gt;&quot;, ··· &quot;&lt;dest&gt;&quot;] 2.10 ENV设置环境变量 123456ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ···# 例如ENV JAVA_HOME /usr/local/jdkENV MYSQL_ROOT_PASSWORD=123456 VERSION=1.0 NAME=&quot;Hello docker&quot; 2.11 WORKDIR为 RUN、CMD、ENTRYPOINT 以及 COPY 和 ADD 设置工作目录 1234WORKDIR /path/workdir# 例如WORKDIR /root 2.12 USER设置启动容器的用户 12345USER &lt;user&gt;[:&lt;usergroup&gt;]USER &lt;UID&gt;[:&lt;UID&gt;]# 例如USER root 2.13 VOLUME实现文件挂载功能，可以将主机目录挂载到容器中，一般的使用场景为需要持久化存储数据时 1VOLUME [&quot;/data&quot;] 2.14 ARG在构建镜像时，传入一些参数 123456ARG &lt;name&gt;[=&lt;default value&gt;]# 例如ARG version=1.0ARG userUSER $user 在 docker build 构建镜像的时候，使用 --build-arg 来指定参数，若未指定参数则会使用默认值，若未指定默认值就会报错 1docker build --build-arg user=root -t myimage:1.0 . 2.15 HEALTHCHECK健康检查，即指定如何测试容器以检查它是否仍在工作 123456HEALTHCHECK [OPTIONS] CMD commandHEALTHCHECK NONE # 在基础镜像中取消健康检查命令# 例如HEALTHCHECK --interval=5m --timeout=3s --start-period=0s --retries=3 \\ CMD curl -f http:/localhost/ || exit 1 OPTIONS： --interval=DURATION ：每隔多长时间探测一次，默认30秒 --timeout=DURATION ：服务响应超时时长，默认30秒 --start-period=DURATION ：服务启动多久后开始探测，默认0秒 --retries=N ：认为检测失败几次为宕机，默认3次 返回值： 0 ：容器健康，随时可以使用 1 ：容器不健康，无法使用 2 ：保留值","link":"/2020/02/21/dockerfile/"},{"title":"Git 仓库中脚本无执行权限问题的解决方法","text":"参考why-when-i-use-github-actions-ci-for-a-gradle-project-i-face-gradlew-permiss 问题描述由于在 Windows 环境下写脚本时对权限问题不太敏感，并没有为仓库中的脚本赋予执行权限，因此在 actions 执行过程中报了以下错误 12/home/runner/work/_temp/35b69792-52fd-48f2-9411-ec8be68d25ef.sh: line 1: /home/runner/work/bark-action/bark-action/.//script.sh: Permission deniedError: Process completed with exit code 126. 原因是因为 script.sh 没有执行权限 解决方法使用 --chmod=(+|-)x 12--chmod=(+|-)x Set the execute permissions on the updated files. 为仓库中的脚本赋予执行权限 1git update-index --chmod=+x script.sh commit 并 push 后，问题就解决了","link":"/2021/02/07/git-permission-denied/"},{"title":"GitHub Actions 中 python 脚本获取仓库 secrets","text":"GitHub Actions 提供的 CI/CD（持续集成/持续部署） 服务非常方便，可以帮助我们自动完成一些功能。但是当我们在跑一些脚本的时候，不免会存放一些密码、密钥之类的内容。我们期望跑脚本的同时，不以明文的方式存储这类密码 将 GitHub Actions 与 GitHub 仓库的 Secrets 结合，可以轻松帮助我们满足这项需求 下面以基于 ServerChan 的 LeetCode 周赛提醒功能为例 1. 添加 SecretsServerChan 的推送功能需要设置 SCKEY 字段，但是该字段不应以明文方式存储 打开仓库「Settings」中的「Secrets」，点击「New secret」 2. 配置 GitHub Actions用来向 ServerChan 接口发送请求的文件名为 main.py git bash 中键入命令，新建文件 1mkdir -p .github/workflows &amp;&amp; touch .github/workflows/leetcode-weekly.yml 编辑 leetcode-weekly.yml，键入以下内容 12345678910111213141516171819202122232425name: 'GitHub Actions LeetCode Weekly Bot'on: push: branches: - master schedule: - cron: '0 2 * * 0'jobs: leetcode-weekly: runs-on: ubuntu-latest steps: - name: 'Checkout' uses: actions/checkout@v2 - name: 'Set up Python' uses: actions/setup-python@v1 with: python-version: 3.7 - name: 'Install requirements' run: pip install -r leetcode-weekly/requirements.txt - name: 'Working' env: SCKEY: ${{ secrets.SCKEY }} run: python leetcode-weekly/main.py 其中，在 Working 步骤中，指定了环境变量 SCKEY，并将它的 value 设为 secrets.SCKEY 3. python 脚本中获取环境变量1234import osif __name__ == '__main__': SCKEY = os.environ[&quot;SCKEY&quot;] 同理，对于一些需要登录的脚本也可以使用以上方式实现加密","link":"/2020/06/01/github-actions-secret/"},{"title":"GitHub Actions 发布至 GitHub Marketplace","text":"GitHub Actions 是 GitHub 提供的一款 CI/CD（持续集成/持续部署）工具，可以帮助我们自动构建、测试、编译、打包、部署项目，功能十分强大 GitHub Marketplace 中收录了许多官方和第三方开发者所发布的一系列 actions 下面以本人所发布的 Bark Notify 为例，讲述将自己开发的 action 发布到 GitHub Marketplace 的详细过程以及在开发过程中遇到的坑 编写 metadata fileaction 由一个 YAML 语法的元数据文件所定义，因此须在仓库中新建一个 action.yml 或 action.yaml 文件作为 action 的入口 You can create actions to perform tasks in your repository. Actions require a metadata file that uses YAML syntax. ——Metadata syntax for GitHub Actions 以下是元数据文件中的几个关键字段 name: action 的名称，也是在 GitHub Marketplace 中所展示的名称 author: 作者信息 description: aciton 的简短描述 inputs: 定义输入参数集合，可以包含多个参数 inputParamterName: 输入参数名称 description: 输入参数描述 required: 是否必填，是一个 bool 变量 default: 默认值 outputs: 定义输出参数集合，可以包含多个参数 outputParamterName: 输出参数名称 description: 输出参数描述 runs: 配置 action 代码的路径和用于执行代码的应用程序 branding: 在 GitHub Marketplace 中显示的图标样式 icon: 图标名称，须从Feather 中选取 color: 图标颜色，可以使以下 8 种颜色：white、yellow、blue、green、orange、red、purple 或 gray-dark 定义输入参数inputs 对象定义了 action 所依赖的输入参数，根据 官方文档 中的描述，输入参数会被存储到名为 INPUT_&lt;VARIABLE_NAME&gt; 的环境变量中，参数名称会被转换为大写，空格替换为 _ 字符，action 代码中可以读取该环境变量从而得到输入参数的值 例如，inputs 中所定义的 inputParamterName输入参数的值，会被存储到名为 INPUT_INPUTPARAMTERNAME 的环境变量中 但是，尽管官方文档中这样说，但在使用的过程中却遇到了坑。所定义的输入参数并不能够直接通过读取该环境变量取值，事实上通过在执行过程中打印日志，在环境变量中并没有发现输入参数 因此，解决办法是手动将其定义到 env 对象中，这样在脚本中就可以通过 $INPUT_&lt;PARAMTER_NAME&gt; 获取到输入变量的值了 12345678910111213steps: - name: Run script shell: bash run: $GITHUB_ACTION_PATH/script.sh env: INPUT_KEY: ${{ inputs.key }} INPUT_TITLE: ${{ inputs.title }} INPUT_BODY: ${{ inputs.body }} INPUT_SOUND: ${{ inputs.sound }} INPUT_ISARCHIVE: ${{ inputs.isArchive }} INPUT_URL: ${{ inputs.url }} INPUT_AUTOMATICALLYCOPY: ${{ inputs.automaticallyCopy }} INPUT_COPY: ${{ inputs.copy }} 对于不方便公开的输入参数，例如密码、私钥等，可以先保存至仓库的 Secrets 中，传入时通过以下方式传入 1234- name: Push notifications uses: shink/bark-action@v1 with: key: ${{ secrets.KEY }} 定义运行步骤action 支持 JavaScript、Docker 和 组合运行三种运行步骤方式 JavaScript 运行方式示例： 123runs: using: 'node12' main: 'main.js' 可参考 官方文档 Docker 运行方式123runs: using: 'docker' image: 'docker://debian:stretch-slim' 可参考 官方文档 组合运行方式示例： 12345runs: using: &quot;composite&quot; steps: - run: ${{ github.action_path }}/test/script.sh shell: bash 组合运行方式支持各类脚本，更加灵活易用 using: 组合运行方式必须设置为 composite steps: 运行步骤集合，可以包含多个步骤，每个步骤顺序执行 name: 步骤名称 id: 该步骤的唯一标识 shell: 运行方式，支持 using-a-specific-shell 中所列的所有 shell，常用的有 bash、python run: 脚本文件路径 env: 仅用于该步骤的环境变量 working-directory: 工作目录路径 示例shink/bark-action 中的 action.yml示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546name: 'Bark Action'description: 'An action for bark'author: Ji Yuanhao &lt;jiyuanhao1997@gmail.com&gt;branding: icon: 'message-circle' color: 'red'inputs: key: description: Secret key required: true title: description: Message title required: false body: description: Message body required: false sound: description: Message sound required: false isArchive: description: Whether to archive this message required: false url: description: URL to redirect required: false automaticallyCopy: description: Whether to copy this message automatically required: false copy: description: Content copied to clipboard required: falseruns: using: &quot;composite&quot; steps: - name: Run script shell: bash run: $GITHUB_ACTION_PATH/script.sh env: INPUT_KEY: ${{ inputs.key }} INPUT_TITLE: ${{ inputs.title }} INPUT_BODY: ${{ inputs.body }} INPUT_SOUND: ${{ inputs.sound }} INPUT_ISARCHIVE: ${{ inputs.isArchive }} INPUT_URL: ${{ inputs.url }} INPUT_AUTOMATICALLYCOPY: ${{ inputs.automaticallyCopy }} INPUT_COPY: ${{ inputs.copy }} 至此，编写好 action.yml 文件后，在当前仓库中的 .github/workflows/&lt;CI_NAME&gt;.yml 中就可以通过以下方式使用自定义的 action 了 12- name: Run my action uses: ./ 例如，在 shink/bark-action 的 .github/workflows/push-notification.yml 中： 123456789101112131415161718192021222324name: 'Push Notifications to Bark'on: repository_dispatch: workflow_dispatch:jobs: job: name: Push notification job runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: Push notifications uses: ./ with: key: ${{ secrets.KEY }} title: Message title body: Message body sound: alarm isArchive: 1 url: https://yuanhaoji.com automaticallyCopy: 1 copy: Content copied to clipboard 发布至 GitHub Marketplace编写好 action.yml 及运行代码后，就可以发布至 GitHub Marketplace 供他人使用了 如果仓库根目录下有 action.yml 或 action.yaml 文件，仓库页面上方就会提示是否需要发布 点击 Draft a release 按钮，进入发布页面，勾选 Publish this Action to the GitHub Marketplace 会自动检测 action.yml 文件中是否包含必填字段，以及仓库中是否有 README.md 文档 填写 Primary Category 和 Another Category，为 action 选择类别 接下来是 Tag，输入 Tag version，建议使用 v1、v1.2.3 等作为标签版本名称 最后是 Release，填写 Release title 和 Release description，点击 Publish release 后即可完成发布 发布完成后，即可在 GitHub Marketplace 页面看到自己发布的 action 参考Github action 的开发到发布 Metadata syntax for GitHub Actions","link":"/2021/02/07/github-actions-publish-marketplace/"},{"title":"GitHub Actions 部署爬虫并定时发送邮件","text":"本文将介绍如何在 GitHub Actions 上部署爬虫并定时发送邮件，无需额外购买服务器 1. GitHub ActionsGitHub Actions 是在 GitHub Universe 大会上发布的，被 Github 主管 Sam Lambert 称为 “再次改变软件开发” 的一款重磅功能（“we believe we will once again revolutionize software development.”）。于 2018 年 10 月推出，内测了一段时间后，于 2019 年 11 月 13 日正式上线 GitHub 会提供一个以下配置的服务器做为 runner： 2-core CPU 7 GB of RAM memory 14 GB of SSD disk space （免费额度最多可以同时运行 20 个作业，心动了有木有💘） GitHub Actions 是一个 CI/CD（持续集成/持续部署）工具，持续集成由很多操作组成，比如 抓取代码、运行测试、登录远程服务器、发布到第三方服务 等等。GitHub 把这些操作统称为 actions actions 是 GitHub Actions 的核心，简单来说，它其实就是一段可以执行的代码，可以用来做很多事情。比如，你在 python 3.7 环境下写了一个 python 项目放到了 GitHub 上，但是考虑到其他用户的生产环境各异，可能在不同的环境中运行结果都不一样，甚至无法安装，这时你总不能在自己电脑上把所有的 python 环境都测试一遍吧 但是如果有了 GitHub Actions，你可以在 runner 服务器上部署一段 actions 代码来自动完成这项任务。你不仅可以指定它的操作系统（支持 Windows Server 2019、Ubuntu 18.04、Ubuntu 16.04 和 macOS Catalina 10.15），还可以指定触发时机、指定 python 版本、安装其他库等等 此外，它还可以用来做很多有趣的事，比如当有人向仓库里提交 issue 时，给你的微信发一条消息；爬取课程表，每天早上准时发到你的邮箱；当向 master 分支提交代码时，自动构建 Docker 镜像并打上标签发布到 Docker Hub 上 …… 慢慢的，你会发现很多操作在不同项目里面是类似的，完全可以共享。GitHub 也注意到了这一点，于是它允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用 总而言之，GitHub Actions 就是为我们提供了一个高效易用的 CI/CD（持续集成/持续部署）工作流，帮助我们自动构建、测试、部署我们的代码 具体的用法可以参考这些资料： 阮一峰老师的一篇文章：GitHub Actions 入门教程 GitHub Actions 中文文档：GitHub Actions Documentation GitHub Actions 官方市场：Actions Marketplace 熟悉了基本用法之后，本文将通过一个简单的爬虫例子，演示如何在 GitHub Actions 上部署爬虫，并定时发送邮件 完整代码可以从 GitHub 仓库 shink/actions-bot 获取，里面包含了几个基于 GitHub Actions 的小机器人（有福利哦 😏） 2. 步骤爬虫内容就不细说了，这里以一个特别简单的例子为例——爬取 CSDN 用户的 profile 信息，即 https://blog.csdn.net/sculpta 这个页面中左边一栏的访问量、排名等信息，并定时发送到邮箱 2.1 准备爬虫可以先 star 并 fork 本仓库（推荐）或 clone git clone https://github.com/shink/actions-bot.git 👇 修改 CSDN_ID 12345678#!/bin/bashset -eux# 修改为你的CSDN_IDCSDN_ID=&quot;sculpta&quot;python csdn-emailbot/spider.py $CSDN_ID 2.2 开通邮件免费发送服务以网易邮箱为例，选择「设置」中的 「POP3/SMTP/IMAP」，打上勾 ✔ 之后保存，然后设置密码 注意：该密码不能跟邮箱密码一致 2.3 配置 GitHub Actions触发 GitHub Actions 需要在项目仓库新建一个 .github/workflows 子目录，里面存放 YAML 格式配置文件 12345678name: 'GitHub Actions CSDN Email Bot'on: push: branches: - master schedule: - cron: '0 14 * * *' 👆 上面代码中，name 是该配置文件的名字，on 是触发条件，我们指定两种情况下触发，第一种是向 master 分支 push 代码时触发，第二种是定时任务，每天在国际标准时间 14 点（北京时间 22 点）运行 需要注意的是，必须使用 POSIX cron 语法 安排工作流程在特定的 UTC 时间（国际标准时间，等于北京时间减去 8 个小时）运行，并且最短间隔为每 5 分钟一次 计划任务语法有五个字段，中间用空格分隔，每个字段代表一个时间单位 ┌───────────── minute (0 - 59)│ ┌───────────── hour (0 - 23)│ │ ┌───────────── day of the month (1 - 31)│ │ │ ┌───────────── month (1 - 12 or JAN-DEC)│ │ │ │ ┌───────────── day of the week (0 - 6 or SUN-SAT)│ │ │ │ ││ │ │ │ ││ │ │ │ │* &nbsp;* &nbsp;* &nbsp;* &nbsp;* 可在这五个字段中使用以下运算符： 运算符 描述 示例 * 任意值 * * * * * 在每天的每分钟运行 , 值列表分隔符 2,10 4,5 * * * 在每天第 4 和第 5 小时的第 2 和第 10 分钟运行 - 值的范围 0 4-6 * * * 在第 4、5、6 小时的第 0 分钟运行 / 步骤值 20/15 * * * * 从第 20 分钟到第 59 分钟每隔 15 分钟运行（第 20、35 和 50 分钟） 注：GitHub 操作 不支持非标准语法 @yearly、@monthly、@weekly、@daily、@hourly 和 @reboot 👇 接下来，定义了一个名为 csdn-emailbot 的 job，其中包含许多步骤，它们会按顺序依次执行 123456jobs: csdn-emailbot: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 👆 上面代码中，run-on 字段指定当前 job 的运行环境为最新版的 ubuntu 系统。 接下来的 steps 中，第一步是从当前仓库中获取代码，使用的是官方提供的 checkout action 的 2.0.0 版本 123456- name: 'Set up Python' uses: actions/setup-python@v1 with: python-version: 3.7- name: 'Install lib' run: pip install -r ./csdn-emailbot/requirements.txt 👆 上面代码就是 部署爬虫环境 了，首先安装 python 3.7 的环境，然后通过 pip 安装所需要的 beautifulsoup4 和 requests 👇 部署完环境后，就要执行我们写好的爬虫程序了 12- name: 'Working' run: bash ./csdn-emailbot/main.sh 👇 最后，发送邮件 123456789101112- name: 'Send mail' uses: dawidd6/action-send-mail@master with: server_address: smtp.163.com server_port: 465 username: ${{ secrets.MAIL_USERNAME }} password: ${{ secrets.MAIL_PASSWORD }} subject: CSDN Report body: file://email.txt to: shenkebug@qq.com from: GitHub Actions content_type: text/plain 👆 上面代码中，使用了一个开发者写好的 发送邮件的 action，其中需要注意的是，SMTP 服务器的用户名和密码使用的是加密变量，需要在仓库的「Settings」中设置「Secrets」，如下图所示： 其中，MAIL_USERNAME 是你开通 SMTP 服务的邮箱，MAIL_PASSWORD 是你设置的 SMTP 服务的密码（不是邮箱的登录密码） 最后，将 to 修改为你要接受邮件的邮箱地址 👌 写好配置，推送到仓库以后，就可以每天晚上收到一封 CSDN profile 的邮件了 2.4 完整 yml 文件12345678910111213141516171819202122232425262728293031323334353637name: 'GitHub Actions CSDN Email Bot'on: push: branches: - master schedule: - cron: '0 14 * * *'jobs:csdn-emailbot: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: 'Set up Python' uses: actions/setup-python@v1 with: python-version: 3.7 # - name: 'Install dependencies' # run: python -m pip install --upgrade pip - name: 'Install requirements' run: pip install -r ./csdn-emailbot/requirements.txt - name: 'Working' run: bash ./csdn-emailbot/main.sh - name: 'Send mail' uses: dawidd6/action-send-mail@master with: server_address: smtp.163.com server_port: 465 username: ${{ secrets.MAIL_USERNAME }} password: ${{ secrets.MAIL_PASSWORD }} subject: CSDN Report body: file://email.txt to: ${{ secrets.RECEIVER }} from: GitHub Actions content_type: text/plain 另外：GitHub Actions 貌似仅支持保存在工作流程运行过程中产生的文件，当作业完成时，运行程序会终止并删除虚拟环境的实例，文件也会随之清空 如果想实现永久存储，可以利用仓库进行存储，将要保存的文件 push 到仓库里，每次工作运行时再从仓库获取文件，再执行后面的逻辑即可","link":"/2020/02/02/github-actions-spider/"},{"title":"GitHub 多人队伍合作详细教程","text":"本文将分场景详细讲述如何通过 GitHub 实现多人队伍协同开发 示例中所使用的仓库是 shink/cooperation-test，欢迎加入，一起熟练 Git 的使用 开发规范分支管理为了规范开发、保持 commit 历史、方便后期维护，Git 的分支管理是必不可少的工作 分支管理示例： main 分支： 主分支，最终的、稳定的、经过测试没有 bug 的、可部署于生产环境的分支 只能由 release 和 hotfix 分支合并，任何情况下都不能直接修改代码 dev 分支： 主要开发分支，贯穿于整个项目的生命周期 始终保持最新版本，功能模块开发任务交给 feature 分支，测试任务交给 release 分支 hotfix 分支： 热修复分支，当 main 分支部署到生产环境后发生紧急状况，需要及时处理时，该分支负责热修复，即在保证应用不下线的条件下，对 bug 进行紧急修复 该分支以 main 分支为基线，修复 bug 后，合并到 main 分支部署上线，同时也合并到 dev 分支保持最新进度 命名规则： hotfix/NAME 或 hotfix-NAME feature 分支： 功能模块开发分支，对应于一个特定的功能模块 该分支以 dev 分支为基线，完成开发工作后再合并到 dev 分支 命名规则：feature/NAME 或 feature-NAME release 分支： 预发布分支，在发布正式版本前进行全面测试和修复 该分支以 dev 分支为基线进行全面测试，若发生 bug 则可直接在该分支修复并提交 经过测试没有问题之后，合并到 main 分支部署上线，同时也合并到 dev 分支保持最新进度 命名规则：release/NAME 或 release-NAME 分支名称 分支职责 基线分支 合并分支 main 主分支 - - dev 开发分支 main - hotfix 热修复分支 main main, dev feature 功能模块开发分支 dev dev release 预发布分支 dev main, dev 总结： main 分支和 dev 分支都贯穿于整个项目的生命周期 hotfix、feature、release 分支都是临时分支，分别负责热修复、功能模块开发、预发布 下图很好地展示了在时间轴上各分支的职责划分情况 Commit message每次 commit 到本地库时，必须添加 commit message，以对本次提交做出说明 在团队合作时，commit message 的书写格式也应当遵守相应规范，清晰明了的 commit message 有利于快速定位提交、自动生成 change log 文档 下图是 Angular 规范 具体的规范说明可参考阮一峰老师的博客：Commit message 和 Change log 编写指南 任务划分团队合作中，合理的划分任务有助于项目顺利开展 下面以一个二人队伍为例（队长 A 和队员 B），多人队伍的话其他队员操作同队员 B 队长 A 的任务： 统一规范，包括命名规范、文档规范等 review 代码，维护 issue 和 PR，管理 main 分支和 dev 分支 承担部分开发任务 队员 B 的任务： 承担主要开发任务，完成系统功能 初始状态以队长 A 的仓库为基准，首先队员 B Fork 队长 A 的项目仓库 假设仓库初始状态为：main 分支和 dev 分支下分别只有 README.md 文件 123┌── main: README.md│└── dev: README.md 开始时首先 clone 远程仓库到本地 1git clone https://github.com/user/repo.git clone 完之后，可以看到本地仓库中只有 main 分支 123git branch* main 通过下列命令查看所有分支 123456git branch -a* main remotes/origin/HEAD -&gt; origin/main remotes/origin/dev remotes/origin/main 可以看到远程仓库中虽然有 dev 分支，但是本地仓库中并没有分支与远程仓库的 dev 分支关联 通过下列命令在本地仓库中创建并切换到 dev 分支 1git checkout -b dev origin/dev 此时，在本地分支中就可以看到 dev 分支了 1234git branch* dev main 场景一：队员与主仓版本保持同步在开始工作前，须先拉取当前当前分支的最新版本，保证代码是最新版本 以队员 B 为例： 添加主仓的远程仓库地址 1git remote add upstream https://github.com/captain_a/project.git 查看当前仓库所连接的远程仓库 1git remote -v 此时，当前仓库所连接的远程仓库为： 1234origin https://github.com/member_b/project.git (fetch)origin https://github.com/member_b/project.git (push)upstream https://github.com/captain_a/project.git (fetch)upstream https://github.com/captain_a/project.git (push) 切换到 dev 分支 1git checkout dev 获取 upstream 的最新内容 1git fetch upstream dev 合并 1git merge upstream/dev 至此，dev 分支就包含最新版本代码了（main 分支同理） 场景二：队员开发特定功能模块 在开发阶段，应当尽量避免发生冲突，同时保持 commit 历史的干净整洁，善用 git rebase 命令可以保证 commit 历史更加清爽，rebase 的同时还是可以 squash，将逻辑相似的多个 commit 合并到一个 commit，并附上描述性更强的 commit message， 这样 commit 历史就会非常清晰、一目了然了 以队员 B 开发登录模块为例 在本地创建 feature/login_module 分支，首先切换到 dev 分支 1git checkout dev 以 dev 分支为基线，创建 feature/login_module 分支，并切换到该分支 1git checkout -b feature/login_module 查看各分支情况 12345git branch -v dev 333e2b6 Init README.md* feature/login_module 333e2b6 Init README.md main 333e2b6 Init README.md 将该分支 push 到远程仓库 1git push origin feature/login_module:feature/login_module 假设队员 B 完成了开发任务，创建了 login_module.txt 文件 1echo &quot;login module finished&quot; &gt; login_module.txt add 到暂存区 1git add login_module.txt commit 到本地库 1git commit -m &quot;login module finished&quot; push 到远程仓库 1git push origin feature/login_module 在 GitHub 页面可以看到提交成功了 场景三：队员提交 PR，请求与主仓合并队员 B 已经在自己的仓库中完成了功能模块的开发，但并没有合并到队长 A 的仓库中，因此队长 A 目前还无法看到队员 B 所做的工作 队员可以提交 PR，即 Pull Request，请求与主仓进行合并 在提交 PR 时，PR 中尽量只包含一个 commit 此时，队员 B 可以选择先将 feature 分支合并到 dev 分支，再提交 PR，请求合并到主仓的 dev 分支，即 1member_b:dev -&gt; captain_a:dev 也可以请求将 feature 分支合并到主仓的 dev 分支，即 1member_b:feature -&gt; captain_a:dev 还可以请求将 feature 分支合并到主仓的 feature 分支，即 1member_b:feature -&gt; captain_a:feature 这主要取决于主仓是否需要保存临时分支，以及谁负责解决冲突 下面以第一种情况进行演示，即队员 B 先将 feature 分支合并到 dev 分支，再提交 PR，请求合并到主仓的 dev 分支 首先切换到 dev 分支 1git checkout dev 合并 feature 分支 1git merge feature --no-ff merge 时推荐加上 --no-ff 选项，避免 feature 分支扰乱 dev 分支的 commit 历史 若加上了 --no-ff 选项，会自动创建一个 merge 的 commit 记录 输入 commit 信息后，按 Ctrl + O 将 commit 信息保存到 MERGE_MSG 文件中，Ctrl + X 退出 push 到远程仓库 1git push origin dev 可以看到清爽的 commit 历史： 接下来就是提交 PR 阶段了 首先队员 B 在自己的 GitHub 仓库中点击 New pull request 按钮创建 PR 选择分支，然后点击 Create pull request 按钮 填写 title 和 comment后，点击 Create pull request 按钮即可提交 PR 接下来，队长 A 需要打开该 PR 并 review 代码，如果没有问题并且没有冲突则可允许 merge 其中，Merge pull resquest 有三个选项： Create a merge commit ：表示把这个 PR 作为一个分支合并，并保留分支上的所有提交记录 Squash and merge ：表示只为这次合并保留一个提交记录 Rebase and merge ：找到两个分支共同的祖先，然后在当前分支上合并从共同祖先到现在的所有 commit 三个选项的不同点： Create a merge commit ：不能保持 main 分支干净，但是保留了所有的 commit history，当 PR 中 commit 次数较多时不推荐此方式 Squash and merge ：也可以保持 main 分支干净，但是 main 中 author 都是 maintainer，而不是原 author Rebase and merge ：可以尽可能保持 main 分支干净整洁，并且易于识别 author 这里选择 Rebase and merge merge 完成后该 PR 就自动 closed 了，合并工作完成 队长更新本地仓库，在 dev 分支下，拉取最新代码 1git pull origin dev 此时，主仓中的 commit 历史如图所示： 场景四：合并时出现冲突冲突产生有两种情况： 两个分支都修改了同一文件（不管什么地方） 两个分支都修改了同一文件的名称 对于产生的冲突，需要手动修改冲突代码 解决冲突之后，还需要 add 并 commit 123git add CONFLICT_FILEgit commit -m &quot;fix conflict&quot; 场景五：版本回退有时候当前版本可能有许多 bug，不得不重新从头开始工作，这时候就需要先回退到上一版本 git reset 命令可以将当前 branch 回退到之前某一个 commit 节点 回退到上一版本 1git reset HEAD^ 其中，HEAD^ 表示上一个版本，HEAD^^ 表示上上个版本，HEAD~100 表示前 100 个版本 另外，还可以使用以下命令回退到指定版本 1git reset 版本号 版本号可以通过以下命令查看 1git log --oneline 另外，git reset 还有三个选项： --soft: 仅回退本地库中的内容，相当于撤销 git commit --mixed: （默认方式）同时回退本地库和暂存区内容，相当于进一步撤销 git add --hard: 同时回退本地库、暂存区和工作区内容，相当于进一步撤销本地仓库文件夹中的改动 注意：回退版本后，日志中就会删除回退前版本的 commit 记录，如果想查看回退前的版本记录，可以使用如下命令查看 1git reflog","link":"/2020/02/22/github-cooperation/"},{"title":"通过 GitHub Actions 将 GitHub 仓库自动备份到 Gitee、GitLab","text":"前言目前开源已经逐渐形成了一种趋势，越来越多的 geeker 加入了开源大军，开源社区也逐渐壮大，推动了技术发展和快速迭代 作为全球知名的代码托管平台，GitHub、Gitee、GitLab 均拥有不小的用户量，尤其是 GayHub，作为全球最大的同性交友平台，拥有超过 4 千万的用户量，足以说明其在业内的知名度 但是，对于个人来说，使用一个托管平台就足够了，但是我们又有在其他平台备份的需求，并且希望有更新时能够自动备份 对于这种需求，解决办法大多是利用 webhook，或者是在本地仓库中 remote add 添加远程仓库，这样就可以 push 到多个远程仓库。但是这些方法较为繁琐，更何况还有更好用的办法——GitHub Actions，有关 GitHub Actions 的一些教程还可参考博客 GitHub Actions 部署爬虫并定时发送邮件 步骤1. 生成 sshgit bash 中敲入命令，会在 ~/.ssh 文件夹下生成 id_rsa.pub 文件和 id_rsa 文件，分别存放公钥和私钥 1ssh-keygen -t rsa -C &quot;user@email.com&quot; 2. 将公钥添加到 GitLab、GiteeGitee: 「设置」—&gt;「安全设置」—&gt;「SSH公钥」 GitLab: 「Settings」—&gt;「SSH Keys」 3. 将私钥添加到 GitHub 仓库GitHub Repository: 「Settings」—&gt;「Secrets」 4. 取消 GitLab 仓库的受保护分支由于 GitLab 仓库分支默认会受保护，即无法强制推送，如果不取消会报以下错误 1GitLab: You are not allowed to force push code to a protected branch on this project. GitLab Repository: 「Settings」—&gt;「Repository」—&gt;「Protected Branches」 5. 配置 GitHub Actionsgit bash 中敲入命令 1mkdir -p .github/workflows &amp;&amp; touch .github/workflows/mirror.yml 用 VS Code 打开 mirror.yml 或使用 vi 编辑，将下列内容添加其中 123456789101112131415161718192021222324252627282930name: 'GitHub Actions Mirror'on: [push, delete]jobs: mirror_to_gitee: runs-on: ubuntu-latest steps: - name: 'Checkout' uses: actions/checkout@v1 - name: 'Mirror to gitee' uses: pixta-dev/repository-mirroring-action@v1 with: target_repo_url: git@gitee.com:tsund/test.git ssh_private_key: ${{ secrets.GITEE_KEY }} mirror_to_gitlab: runs-on: ubuntu-latest steps: - name: 'Checkout' uses: actions/checkout@v1 - name: 'Mirror to gitlab' uses: pixta-dev/repository-mirroring-action@v1 with: target_repo_url: git@gitlab.com:tsund/test.git ssh_private_key: ${{ secrets.GITLAB_KEY }} 其中，使用了 repository-mirroring-action，定义了两个 job，分别负责备份 Gitee 和 GitLab 仓库，target_repo_url 指明目标仓库的 ssh 地址，ssh_private_key 指明 GitHub 仓库中 Secrets 存放的目标仓库的 ssh 私钥 配置完成后，向 GitHub 仓库 push 时就会自动备份到 Gitee、GitLab 对应的仓库了","link":"/2020/03/16/github-mirror/"},{"title":"搭建 Hadoop 集群详细教程","text":"1. 准备工作1.1 环境 Centos 7 JDK 1.8 Hadoop 2.10.0 1.2 集群部署规划 hadoop1 hadoop2 hadoop3 HDFS NameNode SecondaryNameNode DataNode DataNode DataNode Yarn ResourceManager NodeManager NodeManager NodeManager 2. 配置主节点2.1 创建虚拟机 选择新建虚拟机 选择典型类型 选择稍后安装操作系统 选择 Linux，Centos 7 64位 命名虚拟机 hadoop1 使用默认 20G 磁盘大小 不修改虚拟机硬件配置，完成创建虚拟机 选择创建好的虚拟机，点击编辑虚拟机 移除 USB 控制器、声卡、打印机 选择 CD/DVD，使用 ISO 映像文件，选择 ISO 文件位置 开启并安装虚拟机 时区选 Asia Shanghai 需创建 root 用户 2.2 配置 「编辑」-&gt;「虚拟网络编辑器」-&gt;「VMnet8」-&gt;「设置 NAT」，如下图 虚拟机网络配置选择 NAT 模式 配置静态 ip 切换到 root 用户 1su root 编辑配置文件 1vi /etc/sysconfig/network-scripts/ifcfg-ens32 也有可能是 eth0、ens33 等，跟 Centos 版本有关 配置文件内容如下，其中需要修改 BOOTPROTO 字段值为 static；ONBOOT 字段值为 yes，表示开机启动网络；IPADDR 字段为 ip 地址，需与 NAT 子网 ip 在同一网段；GATEWAY 字段为网关，需与 NAT 网关相同 12345678910111213141516171819TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens32UUID=4d0b744b-8ebf-4c75-b35c-324d9f671ce6DEVICE=ens32ONBOOT=yesIPADDR=192.168.144.101GATEWAY=192.168.144.2DNS1=8.8.8.8DNS2=8.8.4.4 重启网络 1systemctl restart network 查看 ip 1ip addr 关闭防火墙 123systemctl stop firewalld.servicesystemctl disable firewalld.servicesystemctl status firewalld 修改 hostname 1echo hadoop1 &gt; /etc/hostname 编辑文件 1vi /etc/sysconfig/network 写入以下内容 12NETWORKING=yes # 使用网络HOSTNAME=hadoop1 # 设置主机名 配置 Host 1vi /etc/hosts 追加以下内容 123192.168.144.101 hadoop1192.168.144.102 hadoop2192.168.144.103 hadoop3 重启 1reboot 切换回普通用户 1su shenke 创建安装目录 1sudo mkdir /opt/module 修改安装目录所有者 1sudo chown shenke:shenke /opt/module 2.3 安装 JDK 将在 /tmp 目录下的 jdk-8u261-linux-x64.tar.gz 解压 1tar -zxvf jdk-8u261-linux-x64.tar.gz 移动到 /opt/module 目录下，并重命名为 jdk 1mv jdk1.8.0_261 /opt/module/jdk 配置环境变量 1sudo vi /etc/profile 追加以下内容 123# JAVA_HOMEexport JAVA_HOME=/opt/module/jdkexport PATH=$PATH:$JAVA_HOME/bin 使环境变量生效 1source /etc/profile 验证是否安装成功 1java -version 2.4 安装 Hadoop 将在 /tmp 目录下的 hadoop-2.10.0.tar.gz 解压 1tar -zxvf hadoop-2.10.0.tar.gz 移动到 /opt/module 目录下，并重命名为 hadoop 1mv hadoop-2.10.0 /opt/module/hadoop 配置环境变量 1sudo vi /etc/profile 追加以下内容 1234# HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoopexport PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin 使环境变量生效 1source /etc/profile 验证是否安装成功 1hadoop 2.5 安装其他包1sudo yum install -y net-tools rsync 3. 配置从节点3.1 克隆虚拟机先将 hadoop1 关机，「右键」-&gt;「管理」-&gt;「克隆」 选择创建完整克隆 修改虚拟机名称为 hadoop2 3.2 配置网络如 2.2 中第 3 步，修改 /etc/sysconfig/network-scripts/ifcfg-ens32 文件中的 IPADDR 为 192.168.144.102，并删除 UUID 如 2.2 中第 5 步，修改 hostname 为 hadoop2 重复以上步骤，克隆一个 hadoop3 节点 3.3 测试尝试能否 ping 通其他节点 1ping hadoop2 4. 配置集群4.1 设置 SSH 无密码登录 生成公钥 1ssh-keygen -t rsa 分发公钥 123ssh-copy-id hadoop1ssh-copy-id hadoop2ssh-copy-id hadoop3 在三个节点上重复以上命令 4.2 编写集群分发脚本 xsync 在 hadoop1 的 /home/user/bin 目录下创建 xsync 文件 1mkdir bin &amp;&amp; touch bin/xsync 如果是 root 用户则可将脚本放在 /usr/local/bin 目录下 编辑脚本 1vi bin/xsync 内容参考 xsync.sh，主要是通过以下命令实现文件同步，其中，-r 表示递归处理子目录，-v 表示以详细模式输出，-l 表示保留软链接，--delete 表示同步删除，--ignore-errors 表示即使出现 IO 错误也进行删除 1rsync -rvl --delete --ignore-errors $directory/$file $user@$host:$directory 赋予执行权限 1chmod 777 bin/xsync 使用 1234xsync $file# 例如xsync /home/shenke/bin 5. 配置集群配置文件均在 hadoop 安装目录下的 etc/hadoop 目录下 5.1 核心配置文件 编辑 core-site.xml 1vi core-site.xml 在 configuration 标签中写入以下内容 123456789101112131415&lt;configuration&gt; &lt;!-- 指定 HDFS 中 NameNode 的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop1:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定 Hadoop 运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 创建存储目录 1mkdir -p /opt/module/hadoop/data/tmp 5.2 HDFS 配置文件 配置 hadoop-env.sh 1vi hadoop-env.sh 在文件末尾追加以下内容 1export JAVA_HOME=/opt/module/jdk 配置 hdfs-site.xml 1vi hdfs-site.xml 在 configuration 标签中写入以下内容 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定 Hadoop 辅助名称节点主机配置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop3:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.3 Yarn 配置文件 配置 yarn-env.sh 1vi yarn-env.sh 在文件末尾追加以下内容 1export JAVA_HOME=/opt/module/jdk 配置 yarn-site.xml 1vi yarn-site.xml 在 configuration 标签中写入以下内容 123456789101112131415&lt;configuration&gt; &lt;!-- Reducer 获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定 YARN 的 ResourceManager 的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.4 MapReduce 配置文件 配置 mapred-env.sh 1vi mapred-env.sh 在文件末尾追加以下内容 1export JAVA_HOME=/opt/module/jdk 配置 mapred-site.xml 1cp mapred-site.xml.template mapred-site.xml &amp;&amp; vi mapred-site.xml 在 configuration 标签中写入以下内容 123456789&lt;configuration&gt; &lt;!-- 指定 MapReduce 运行在 Yarn 上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.5 配置 slaves编辑 slaves 1vi slaves 写入以下内容 123hadoop1hadoop2hadoop3 5.6 同步配置文件1xsync /opt/module/hadoop 6. 启动集群在 hadoop 安装目录下 格式化 1bin/hdfs namenode -format 如果需要重新格式化 NameNode，需要先将 data/tmp 和 logs下的文件全部删除 启动 HDFS 1sbin/start-dfs.sh 启动 Yarn 1sbin/start-yarn.sh 注意：需在 ResouceManager 所在节点启动 Yarn，本例中在 hadoop2 中启动 查看进程 1jps 查看 web 端 NameNode: hadoop1:50070 SecondaryNameNode: hadoop3:50090 停止 HDFS 1sbin/stop-dfs.sh 停止 Yarn 1sbin/stop-yarn.sh 7. 编写群起脚本 启动和关闭脚本 同样是在 /home/shenke/bin 目录下，新建并编辑脚本 1vi ~/bin/hdp 内容参考 hadoop.sh 查看进程脚本 新建并编辑脚本 1vi ~/bin/xcall 内容参考 xcall.sh 8. HDFS 测试 上传文件 上传一个小文件到根目录 1bin/hdfs dfs -put /home/shenke/bin/xsync / 上传一个大文件到根目录 1bin/hdfs dfs -put /tmp/hadoop-2.10.0.tar.gz / 查看文件存储路径","link":"/2020/08/06/install-hadoop-cluster/"},{"title":"搭建 Kafka 集群详细教程","text":"下面以 搭建 Zookeeper 集群详细教程 中搭建的 zookeeper 集群为例 1. 安装 Kafka 将在 /tmp 目录下的 kafka_2.11-2.4.1.tgz 解压 1tar -zxvf kafka_2.11-2.4.1.tgz 移动到 /opt/module 目录下，并重命名为 kafka 1mv kafka_2.11-2.4.1 /opt/module/kafka 配置环境变量 1sudo vi /etc/profile 追加以下内容 123# KAFKA_HOMEexport KAFKA_HOME=/opt/module/kafkaexport PATH=$PATH:$KAFKA_HOME/bin 使环境变量生效 1source /etc/profile 还需分别在其他节点手动配置环境变量 2. 配置集群2.1 配置 server.properties在 Kafka 安装目录下，编辑 config/server.properties 文件 1vi config/server.properties 修改以下内容 1234broker.id=0log.dirs=/opt/module/kafka/logslisteners=PLAINTEXT://hadoop1:9092zookeeper.connect=hadoop1:2181,hadoop2:2181,hadoop3:2181 注意：broker.id 须为全局唯一的 int 值，在本例中，hadoop1 为 0，hadoop2 为 1，hadoop3 为 2；listeners 也要与所在节点对应 2.2 修改生产者配置文件编辑 config/producer.properties 1vi config/producer.properties 修改以下内容 1bootstrap.servers=hadoop1:9092,hadoop2:9092,hadoop3:9092 2.3 修改消费者配置文件编辑 config/consumer.properties 1vi config/consumer.properties 修改以下内容 1bootstrap.servers=hadoop1:9092,hadoop2:9092,hadoop3:9092 2.4 同步文件1xsync /opt/moudle/kafka 脚本内容可参考 xsync.sh 在其他节点修改 config/server.properties 中的 broker.id 和 listeners 3. 启动集群 启动 Kafka 集群前需要先启动 Zookeeper 1zookeeper start 在每个节点分别启动 Kafka 1bin/kafka-server-start.sh -daemon config/server.properties 关闭集群 在每个节点分别关闭 Kafka 1bin/kafka-server-stop.sh 4. 编写群起脚本在 /home/shenke/bin 目录下，新建并编辑脚本 1vi ~/bin/kafka 内容参考 kafka.sh 使用 12345# 开启kafka start# 停止kafka stop 5. 集群测试5.1 创建主题创建一个副本数为 1、分区数为 3、名为 test 的主题 1bin/kafka-topics.sh --zookeeper hadoop1:2181 --create --replication-factor 1 --partitions 3 --topic test 5.2 查看主题 列出所有主题 1bin/kafka-topics.sh --zookeeper hadoop1:2181 --list 查看某个主题的详情 1bin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic test 5.3 删除主题1bin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic test 5.4 生产消息在 hadoop1 中生产消息 1bin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic test 5.5 消费消息在 hadoop2 中消费消息 1bin/kafka-console-consumer.sh --bootstrap-server hadoop2:9092 --topic test","link":"/2020/08/07/install-kafka-cluster/"},{"title":"搭建 Zookeeper 集群详细教程","text":"下面以 搭建 Hadoop 集群详细教程 中搭建的 hadoop 集群为例 1. 安装 Zookeeper 将在 /tmp 目录下的 zookeeper-3.4.14.tar.gz 解压 1tar -zxvf zookeeper-3.4.14.tar.gz 移动到 /opt/module 目录下，并重命名为 zookeeper 1mv zookeeper-3.4.14 /opt/module/zookeeper 配置环境变量 1sudo vi /etc/profile 追加以下内容 123# ZK_HOMEexport ZK_HOME=/opt/module/zookeeperexport PATH=$PATH:$ZK_HOME/bin 使环境变量生效 1source /etc/profile 还需分别在其他节点手动配置环境变量 2. 配置集群2.1 配置节点编号 在 Zookeeper 安装目录下创建 data 目录，并在该目录下创建 myid 文件 1mkdir data &amp;&amp; touch data/myid 在 myid 中填写与节点对应的编号 1echo 1 &gt; data/myid 2.2 配置 zoo.cfg 文件 重命名 conf 目录下的 zoo_sample.cfg 为 zoo.cfg 1mv conf/zoo_sample.cfg conf/zoo.cfg 编辑文件 1vi conf/zoo.cfg 修改数据存储路径配置 1dataDir=/opt/module/zookeeper/data 追加以下内容 123server.1=hadoop1:2888:3888server.2=hadoop2:2888:3888server.3=hadoop3:2888:3888 2.3 同步文件1xsync /opt/moudle/zookeeper 脚本内容可参考 xsync.sh 在其他节点修改 myid 与节点对应，如本例中，hadoop1 为 1，hadoop2 为 2，hadoop3 为 3 1echo 2 &gt; data/myid 3. 启动集群在各个节点分别启动 Zookeeper 1bin/zkServer.sh start 查看状态 1bin/zkServer.sh status 停止 Zookeeper 1bin/zkServer.sh stop 如果配置了环境变量的话，在任意位置使用 zkServer.sh COMMAND 即可 4. 编写群起脚本在 /home/shenke/bin 目录下，新建并编辑脚本 1vi ~/bin/zookeeper 内容参考 zookeeper.sh 使用 12345678# 开启zookeeper start# 停止zookeeper stop# 查看状态zookeeper status","link":"/2020/08/07/install-zookeeper-cluster/"},{"title":"知识图谱 KBQA Demo：fuseki sparql python 版本问题详细解决方案","text":"刚入坑知识图谱，看了一位大神的教程，但是由于 jena、fuseki、python 等版本不同，踩了不少坑，特此记录一下 本文不做具体知识的讲解（具体知识可移步 https://zhuanlan.zhihu.com/knowledgegraph），仅罗列实践过程中遇到的坑及解决方案 以下内容大多从教程下面几百条评论中提炼总结而来 环境版本 jena ：3.14.0 fuseki ：3.14.0 jdk ：1.8.0_201 python ：3.7.6 anaconda ：4.8.2 具体问题及解决方案1. 通过 D2RQ 生成 mapping 文件此时须打开 MySQL 服务，进入 D2RQ 目录 1generate-mapping -u root -p 密码 -o kg_demo_movie_mapping.ttl jdbc:mysql:///kg_demo_movie?useSSL=false -u ：指定 mysql 用户名 -p ：指定用户密码 -o ：指定输出文件路径及名称 jdbc:mysql:/// 后面指定 mysql 中的数据库名称 对于博主的 kg_demo_movie 项目，mapping 文件生成后还需要修改，所以直接使用博主 GitHub 仓库中的 mapping 文件即可 2. 通过 D2RQ 将数据转为 RDF同样需要打开 MySQL 服务，在 D2RQ 目录下 1.\\dump-rdf.bat -o kg_demo_movie.nt .\\kg_demo_movie_mapping.ttl 3. 添加环境变量在系统变量中，添加以下变量 JENA_HOME ：jena 压缩包的解压位置，例如 D:\\apache-jena FUSEKI_HOME ：fuseki 压缩包的解压位置，例如 D:\\apache-jena\\apache-jena-fuseki 在系统变量中，追加以下变量 CLASSPATH ：追加 %JENA_HOME%\\lib path ：添加 %JENA_HOME%\\bin、%JENA_HOME%\\bat、%FUSEKI_HOME% 4. 通过 Jena 将 RDF 数据以 TDB 方式存储存放在 jena 的 tdb 目录下 1.\\tdbloader.bat --loc=&quot;D:\\apache-jena\\tdb&quot; &quot;D:\\D2RQ\\kg_demo_movie.nt&quot; 5. 使用 OWL 推理机注意：博主用的 fuseki 3.5 版本，其中不少语法在 3.14 版本中已经有所改动，所以直接使用下面的配置文件，只需修改其中本体文件及 TDB 的路径即可 123456789101112131415161718192021222324252627282930313233343536373839@prefix : &lt;http://base/#&gt; .@prefix tdb: &lt;http://jena.hpl.hp.com/2008/tdb#&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .@prefix ja: &lt;http://jena.hpl.hp.com/2005/11/Assembler#&gt; .@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .@prefix fuseki: &lt;http://jena.apache.org/fuseki#&gt; .&lt;#service1&gt; rdf:type fuseki:Service ; fuseki:name &quot;kg_demo_movie&quot; ; fuseki:serviceQuery &quot;sparql&quot; ; fuseki:serviceQuery &quot;query&quot; ; fuseki:serviceUpdate &quot;update&quot; ; fuseki:serviceUpload &quot;upload&quot; ; fuseki:serviceReadWriteGraphStore &quot;data&quot; ; fuseki:serviceReadGraphStore &quot;get&quot; ; fuseki:dataset &lt;#dataset&gt; ; .&lt;#dataset&gt; rdf:type ja:RDFDataset ; ja:defaultGraph &lt;#model_inf&gt; ; .&lt;#model_inf&gt; rdf:type ja:InfModel ; ja:MemoryModel &lt;#tdbGraph&gt; ; #本体文件的路径 ja:content [ja:externalContent &lt;file:///D:/apache-jena/apache-jena-fuseki/run/databases/ontology.ttl&gt; ] ; #启用OWL推理机 ja:reasoner [ja:reasonerURL &lt;http://jena.hpl.hp.com/2003/OWLFBRuleReasoner&gt;] .&lt;#tdbGraph&gt; rdf:type tdb:GraphTDB ; tdb:dataset &lt;#tdbDataset&gt; ; .&lt;#tdbDataset&gt; rdf:type tdb:DatasetTDB ; tdb:location &quot;D:/apache-jena/tdb&quot; ; . 注意：修改配置文件后，还需要将 RDF 数据（即 .nt 文件）上传到 fuseki 中，如图（这个坑真的填了好久 ···） 6. 自定义推导规则注意：rules.ttl 文件中需要用逗号隔开，如下 12345678@prefix : &lt;http://www.kgdemo.com#&gt; .@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .[ruleComedian: (?p :hasActedIn ?m), (?m :hasGenre ?g), (?g :genreName '喜剧') -&gt; (?p rdf:type :Comedian)][ruleSymmetric: (?p :hasActedIn ?m) -&gt; (?m :hasActor ?p)] 7. 运行最终 Demo注意：博主使用的是 python2，其中许多语法在 python3 中也有所改动，修改方法如下 所有的 .decode('utf-8')、.encode('utf-8') 全部删掉，即全部替换为 '' 所有的 iteritems() 替换为 items() 所有的 print content 替换为 print(content)，print 替换为 print('\\n') 所有的 raw_input() 替换为 input() question2sparql.py 文件中第 44 行 return queries_dict.values()[0] 改为 return list(queries_dict.values())[0] 附 PyCharm 全局替换的方法，如图 最终效果","link":"/2020/02/20/kg-demo/"},{"title":"[LeetCode] 动态规划——不同的子序列","text":"题目描述给定一个字符串 s 和一个字符串 t ，计算在 s 的子序列中 t 出现的个数 字符串的一个 子序列 是指，通过删除一些（也可以不删除）字符且不干扰剩余字符相对位置所组成的新字符串。（例如，”ACE” 是 “ABCDE” 的一个子序列，而 “AEC” 不是） 题目数据保证答案符合 32 位带符号整数范围 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/distinct-subsequences著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处 示例示例 1： 1234567891011输入：s = &quot;rabbbit&quot;, t = &quot;rabbit&quot;输出：3解释：如下图所示, 有 3 种可以从 s 中得到 &quot;rabbit&quot; 的方案。(上箭头符号 ^ 表示选取的字母)rabbbit^^^^ ^^rabbbit^^ ^^^^rabbbit^^^ ^^^ 示例 2： 123456789101112131415输入：s = &quot;babgbag&quot;, t = &quot;bag&quot;输出：5解释：如下图所示, 有 5 种可以从 s 中得到 &quot;bag&quot; 的方案。 (上箭头符号 ^ 表示选取的字母)babgbag^^ ^babgbag^^ ^babgbag^ ^^babgbag ^ ^^babgbag ^^^ 提示 0 &lt;= s.length, t.length &lt;= 1000 s 和 t 由英文字母组成 解题思路精选评论1、为啥状态方程这样对？ 我个人习惯 dp[i][j] 表示为 s[0-i] 和 t[0-j] 均闭区间的子序列个数，但这样不能表示s和t空串的情况，所以声明 int[][] dp = new int[m + 1][n + 1]; 这样 dp[0][x] 可以表示 s 为空串，dp[x][0] 同理 先不扣初始化的细节，假设 dp[i][j] 就是s[i] 和 t[j] 索引的元素子序列数量，为啥状态方程是： s[i] == t[j] 时 dp[i][j] = dp[i-1][j-1] + dp[i-1][j]s[i] != t[j] 时 dp[i][j] = dp[i-1][j] 先看s[i] == t[j] 时，以 s = “rara”，t = “ra” 为例，当 i = 3, j = 1 时，s[i] == t[j]，此时分为 2 种情况，s 串用最后一位的 a 或者 不用最后一位的 a，如果用 s 串最后一位的 a,那么 t 串最后一位的 a 也被消耗掉，此时的子序列其实等于 dp[i-1][j-1] 如果不用 s 串最后一位的 a，那就得看 “rar” 里面是否有 “ra” 子序列的了，就是 dp[i-1][j]，所以 dp[i][j] = dp[i-1][j-1] + dp[i-1][j] 再看s[i] != t[j] 比如 s = “rarb”，t = “ra” 还是当 i = 3, j = 1 时，s[i] != t[j]，此时显然最后的 b 想用也用不上啊。所以只能指望前面的 “rar” 里面是否有能匹配 “ra” 的，所以此时dp[i][j] = dp[i-1][j] 2：怎么想到这样的状态方程？ 一点个人经验，见过的很多 2 个串的题，大部分都是 dp[i][j] 分别表示 s 串[0…i] 和 t 串[0…j] 怎么怎么样 然后都是观察 s[i] 和 t[j] 分等或者不等的情况，而且方程通常就是 dp[i-1][j-1] 要么 + 要么 || dp[i-1][j] 类似的 类似的题比如有 10：正则表达式匹配 44：通配符匹配 编辑距离 1143：最长公共子序列 以上内容摘录自评论 个人思考dp[i][j] 表示 s[0-i) 的子序列中 t[0-j) 的数量，因此答案就是 dp[m][n] 要想得出状态 dp[i][j]，就需要考虑什么情况下可以从之前的状态转移而来，之前的状态相当于是 s[0-i) 的子串的子序列中 t[0-j) 的子串的数量，包括 dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1] 因此与当前 s[0-i) 和 t[0-j) 的最后一个字符是否相等有关，若相等，则可以考虑从之前的状态转移过来 若 s[i - 1] == t[j - 1]，则 dp[i][j] = dp[i - 1][j - 1]，但是，上式只考虑了 dp[i - 1][j - 1]，未考虑 dp[i - 1][j] 和 dp[i][j - 1] 以示例中的 s = “rabbbit”，t = “rabbit” 为例，当 s = “rabb”, t = “rab” 时，既可以从 s = “rab” 中搜索 t = “ra” ，也可以从 s = “rab” 中搜索 t = “rab” 而对于子状态 dp[i][j - 1]，尽管两子串最后一个字符已经相等，但是消耗掉 t[j] 的同时也必须消耗掉 s[j]，这样才能保证 若 s[i - 1] ！= t[j - 1]，显然，dp[i][j] = dp[i - 1][j] 代码github.com/shink/LeetCode 1234567891011121314151617181920public int numDistinct(String s, String t) { int m = s.length(), n = t.length(); int[][] dp = new int[m + 1][n + 1]; for (int i = 0; i &lt;= m; i++) { dp[i][0] = 1; } for (int i = 0; i &lt; m; i++) { for (int j = 0; j &lt;= i &amp;&amp; j &lt; n; j++) { if (s.charAt(i) == t.charAt(j)) { dp[i + 1][j + 1] = dp[i][j] + dp[i][j + 1]; } else { dp[i + 1][j + 1] = dp[i][j + 1]; } } } return dp[m][n];}","link":"/2021/03/17/leetcode-distinct-subsequences/"},{"title":"Markdown 语法之数学公式","text":"注：VS Code中需安装插件，如 Markdown All in One 1. 使用 $ 包裹公式使用 $$或$$$ 包裹公式，被包裹的内容会全部展示为 LaTex 公式（使用 $$$$ 包裹的公式会独占一行且水平居中） 小贴士：字体控制，可以使公式更加美观，符号：\\displaystyle 不使用字体控制的情况：$\\frac{x+y}{y+z}$，效果：$\\frac{x+y}{y+z}$ 使用字体控制的情况：$\\displaystyle \\frac{x+y}{y+z}$，效果：$\\displaystyle \\frac{x+y}{y+z}$ 2. 括号、分隔符 下划线，符号：\\underline 或 &lt;u&gt;&lt;/u&gt;如：$\\underline{x + y + z}$，效果：$\\underline{x + y + z}$ 上大括号，符号：\\overbrace{算式}如：$\\overbrace{a+b+c+d}^{2.0}$，效果：$\\overbrace{a+b+c+d}^{2.0}$ 下大括号，符号：\\underbrace{算式}如：$a+\\underbrace{b+c}{1.0}+d$，效果：$a+\\underbrace{b+c}{1.0}+d$ 上位符号，符号：\\stacrel{上位符号}{基位符号}如：$\\vec{x}\\stackrel{\\mathrm{def}}{=}{x_1,\\cdots,x_n}$，效果：$\\vec{x}\\stackrel{\\mathrm{def}}{=}{x_1,\\cdots,x_n}$ 自适应括号，符号：\\left符号 内容 \\right符号在配对符号中可以让括号自动适应公式的高度，如：$\\displaystyle \\left( \\frac{x}{2} \\right)$，效果：$\\displaystyle \\left( \\frac{x}{2} \\right)$ 另：在非配对符号中，使用 \\left. 内容 \\right符号 或 \\left符号 内容 \\right.（注意：有个 . ） 如：$\\displaystyle \\left. \\frac{du}{dx} \\right|{x=0}$，效果：$\\displaystyle \\left. \\frac{du}{dx} \\right|{x=0}$ 3. 公式编号注意：需编号的公式必须独占一行且居中，即 必须使用 $$$$ 符号 常用 \\tag{编号} 或 \\tag*{编号} 编号 说明 \\tag{编号} 公式宏包序号设置命令，可用于带星号公式环境中的公式行 \\tag*{编号} 作用与 \\tag 相同，只是标号两侧 没有圆括号 例如： $$ x^2+y^2=z^2 \\tag{$1.1$} $$ $$ x^2+y^2=z^2 \\tag*{$1.2$} $$ 效果： x^2+y^2=z^2 \\tag{$1.1$}x^2+y^2=z^2 \\tag*{$1.2$}4. 变量表示 描述 符号 表达式 上标 $x^2$ x^2 下标 $y_4$ y_4 矢量 $\\vec{a}$ \\vec{a} $\\hat{a}$ \\hat{a} $\\check{a}$ \\check{a} $\\breve{a}$ \\breve{a} $\\tilde{a}$ \\tilde{a} $\\bar{a}$ \\bar{a} $\\acute{a}$ \\acute{a} $\\mathring{a}$ \\mathring{a} 5. 其他常用符号 描述 符号 表达式 无穷 $\\infty$ \\infty 上箭头 $\\uparrow$ \\uparrow 加粗上箭头 $\\Uparrow$ \\Uparrow 下箭头 $\\downarrow$ \\downarrow 加粗下箭头 $\\Downarrow$ \\Downarrow 左箭头 $\\leftarrow$ \\leftarrow 加粗左箭头 $\\Leftarrow$ \\Leftarrow 右箭头 $\\rightarrow$ \\rightarrow 加粗右箭头 $\\Rightarrow$ \\Rightarrow 底端对齐的省略号 $1,2,\\ldots,n$ \\ldots 中线对齐的省略号 $1 + 2 + \\cdots + n$ \\cdots 竖直对齐的省略号 $\\vdots$ \\vdots 斜对齐的省略号 $\\ddots$ \\ddots 6. 数学运算 除法运算（分数表示），符号：\\frac{分子}{分母} 或 分子 \\over 分母如：$\\frac{1-x}{y+1}$ 或 $x \\over x+y$，效果：$\\frac{1-x}{y+1}$ 或 $x \\over x+y$ 平均数运算，符号：\\overline{算式}如：$\\overline{x + y + z}$，效果：$\\overline{x + y + z}$ 开方运算，符号：\\sqrt[开方数]{被开方数} （开二次方可直接使用 \\sqrt 被开方数 ）如：$\\sqrt x$，效果：$\\sqrt x$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\sqrt[3] y$，效果：$\\sqrt[3] y$ 对数运算，符号：\\log_低数{真数}如：$\\log_5{8}$，效果：$\\log_5{8}$ 极限运算，符号：\\lim如：$\\lim{x \\to +\\infty}{\\frac{1}{x}}$，效果：$\\lim{x \\to +\\infty}{\\frac{1}{x}}$ 建议搭配 \\displaystyle 使用：$\\displaystyle \\lim{x \\to +\\infty}{\\frac{1}{x}}$，效果：$\\displaystyle \\lim{x \\to +\\infty}{\\frac{1}{x}}$ 求和运算，符号：\\sum如：$\\sum^{+\\infty}{i = 1}{\\frac{1}{i}}$，效果：$\\sum^{+\\infty}{i = 1}{\\frac{1}{i}}$ 建议搭配 \\displaystyle 使用：$\\displaystyle \\sum^{+\\infty}{i = 1}{\\frac{1}{i}}$，效果：$\\displaystyle \\sum^{+\\infty}{i = 1}{\\frac{1}{i}}$ 积分运算，符号：\\int 积分 符号 表达式 定积分 $\\int$ \\int 二重积分 $\\iint$ \\iint 三重积分 $\\iiint$ \\iiint 曲线积分 $\\oint$ \\oint 曲面积分 $\\oiint$ \\oiint 如：$\\int^{\\infty}{1}{\\frac{1}{x}dx}$，效果：$\\int^{\\infty}{1}{\\frac{1}{x}dx}$ 建议搭配 \\displaystyle 使用：$\\displaystyle \\int^{\\infty}{1}{\\frac{1}{x}dx}$，效果：$\\displaystyle \\int^{\\infty}{1}{\\frac{1}{x}dx}$ 偏微分运算，符号：\\partial如：$\\frac{\\partial xy^2}{\\partial y}$，效果：$\\frac{\\partial xy^2}{\\partial y}$ 建议搭配 \\displaystyle 使用：$\\displaystyle \\frac{\\partial xy^2}{\\partial y}$，效果：$\\displaystyle \\frac{\\partial xy^2}{\\partial y}$ 矩阵表示，符号：\\begin{matrix} \\end{matrix}如： $$A=\\left(\\begin{matrix}&nbsp;&nbsp;&nbsp;&nbsp;x_{11} \\&amp;x_{12} \\&amp;x_{13} \\&amp;\\cdots \\&amp;x_{1n} \\\\&nbsp;&nbsp;&nbsp;&nbsp;x_{21} \\&amp;x_{22} \\&amp;x_{23} \\&amp;\\cdots \\&amp;x_{2n} \\\\&nbsp;&nbsp;&nbsp;&nbsp;\\vdots \\&amp;\\vdots \\&amp;\\vdots \\&amp;\\ddots \\&amp;\\vdots \\\\&nbsp;&nbsp;&nbsp;&nbsp;x_{n1} \\&amp;x_{n2} \\&amp;x_{n3} \\&amp;\\cdots \\&amp;x_{nn}\\end{matrix} \\right)$$ 效果： A= \\left(\\begin{matrix} x_{11} &x_{12} &x_{13} &\\cdots &x_{1n} \\\\ x_{21} &x_{22} &x_{23} &\\cdots &x_{2n} \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ x_{n1} &x_{n2} &x_{n3} &\\cdots &x_{nn} \\end{matrix} \\right)用竖线将矩阵分割为 (A|b) 形式，如： $$(A|b)=\\left(\\begin{array}{ccccc|c}&nbsp;&nbsp;&nbsp;&nbsp;x_{11} \\&amp;x_{12} \\&amp;x_{13} \\&amp;\\cdots \\&amp;x_{1n} \\&amp;b_1 \\\\&nbsp;&nbsp;&nbsp;&nbsp;x_{21} \\&amp;x_{22} \\&amp;x_{23} \\&amp;\\cdots \\&amp;x_{2n} \\&amp;b_2 \\\\&nbsp;&nbsp;&nbsp;&nbsp;\\vdots \\&amp;\\vdots \\&amp;\\vdots \\&amp;\\ddots \\&amp;\\vdots \\&amp;\\vdots \\\\&nbsp;&nbsp;&nbsp;&nbsp;x_{n1} \\&amp;x_{n2} \\&amp;x_{n3} \\&amp;\\cdots \\&amp;x_{nn} \\&amp;b_n\\end{array} \\right)$$ 效果： (A|b)= \\left(\\begin{array}{ccccc|c} x_{11} &x_{12} &x_{13} &\\cdots &x_{1n} &b_1 \\\\ x_{21} &x_{22} &x_{23} &\\cdots &x_{2n} &b_2 \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots &\\vdots \\\\ x_{n1} &x_{n2} &x_{n3} &\\cdots &x_{nn} &b_n \\end{array} \\right)7. 逻辑运算 逻辑描述 符号 表达式 大于等于 $\\geq$ \\geq 小于等于 $\\leq$ \\leq 不等于 $\\neq$ \\neq 不大于等于 $\\ngeq$ \\ngeq 不小于等于 $\\nleq$ \\nleq 约等于 $\\approx$ \\approx 恒等于 $\\equiv$ \\equiv 8. 集合运算 描述 符号 表达式 属于 $\\in$ \\in 不属于 $\\notin$ \\notin 子集 $\\subseteq$ , $\\supseteq$ \\subseteq , \\supseteq 非子集 $\\not\\subseteq$ , $\\not\\supseteq$ \\not\\subseteq , \\not\\supseteq 真子集 $\\subsetneq$ , $\\supsetneq$ \\subsetneq , \\supsetneq 非真子集 $\\not\\subsetneq$ , $\\not\\supsetneq$ \\not\\subsetneq , \\not\\supsetneq 交集 $\\cap$ \\cap 并集 $\\cup$ \\cup 差集 $\\setminus$ \\setminus 同或 $\\bigodot$ \\bigodot 同与 $\\bigotimes$ \\bigotimes 异或 $\\bigoplus$ \\bigoplus 9. 希腊字母将部分符号的表达式首字母大写，即为相应符号的大写形式 小写符号 表达式 大写符号 表达式 $\\alpha$ \\alpha $\\Alpha$ \\Alpha $\\beta$ \\beta $\\Beta$ \\Beta $\\gamma$ \\gamma $\\Gamma$ \\Gamma $\\delta$ \\delta $\\Delta$ \\Delta $\\epsilon$ \\epsilon $\\Epsilon$ \\Epsilon $\\mu$ \\mu $\\Mu$ \\Mu $\\varepsilon$ \\varepsilon $\\zeta$ \\zeta $\\Zeta$ \\Zeta $\\eta$ \\eta $\\Eta$ \\Eta $\\theta$ \\theta $\\Theta$ \\Theta $\\vartheta$ \\vartheta $\\pi$ \\pi $\\Pi$ \\Pi $\\phi$ \\phi $\\Phi$ \\Phi $\\psi$ \\psi $\\Psi$ \\Psi $\\omega$ \\omega $\\Omega$ \\Omega $\\rho$ \\rho $\\Rho$ \\Rho $\\sigma$ \\sigma $\\Sigma$ \\Sigma $\\xi$ \\xi $\\Xi$ \\Xi $\\partial$ \\partial 10. 字体 黑板粗体（Blackboard bold），符号：\\mathbb{内容} 字体 显示效果 表达式 普通 abcd abcd 普通数学形式 $abcd$ abcd 小写 $\\mathbb{abcd}$ \\mathbb{abcd} 大写 $\\mathbb{ABCD}$ \\mathbb{ABCD} 正粗体，符号：\\mathbf{内容} 字体 显示效果 表达式 普通 abcd abcd 普通加粗 abcd **abcd** 小写 $\\mathbf{abcd}$ \\mathbf{abcd} 大写 $\\mathbf{ABCD}$ \\mathbf{ABCD} 斜体数字，符号：\\mathit{内容} 字体 显示效果 表达式 普通 3.1415 3.1415 普通斜体 3.1415 *3.1415* 斜体 $\\mathit{3.1415}$ \\mathit{3.1415} 罗马体，符号：\\mathrm{内容} 字体 显示效果 表达式 普通 ABCD ABCD 普通数学形式 $ABCD$ ABCD 罗马体 $\\mathrm{ABCD}$ \\mathrm{ABCD} 哥特体，符号：mathfrak{内容} 字体 显示效果 表达式 普通 abcd abcd 普通数学形式 $abcd$ abcd 小写 $\\mathfrak{abcd}$ \\mathfrak{abcd} 大写 $\\mathfrak{ABCD}$ \\mathfrak{ABCD} 手写体，符号：\\mathcal{内容} 字体 显示效果 表达式 普通 abcd abcd 普通数学形式 $abcd$ abcd 小写 $\\mathcal{abcd}$ \\mathcal{abcd} 大写 $\\mathcal{ABCD}$ \\mathcal{ABCD}","link":"/2020/02/02/markdown-math/"},{"title":"Markdown 语法一揽子计划（超详细）","text":"1. 标题使用 #表示 1~6 级标题 # 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 效果： 一级标题二级标题三级标题四级标题五级标题六级标题 2. 文本样式 `标记`*斜体*，_斜体_**粗体**，__粗体__**_斜体+粗体_**\\下划线\\&lt;\\/u>~~删除线~~ 效果： 标记斜体，斜体粗体，粗体斜体+粗体下划线删除线 2.1 字体大小和颜色字体大小使用 &lt;font&gt;&lt;/font&gt; 标签，该标签下的 size 属性为字体大小，范围为 1~7，color 属性为字体颜色，如 red、blue 等 size=1 color=red size=2 color=blue size=3 color=yellow size=4 color=green size=5 color=orange size=6 color=gray size=7 color=purple 3. 链接链接有两种形式：行内式和参考式 行内式 [Google](https://www.google.com “谷歌搜索”) 效果： Google 参考式 [Google][1][Baidu][2] [1]: https://www.google.com “谷歌搜索”[2]: https://www.baidu.com “百度一下” 效果： GoogleBaidu 4. 图片插入图片和插入链接类似，只是需要在链接的基础上前面加一个 ! ![icon](https://gitee.com/tsund/data/raw/master/favicon/favicon-180x180.png “icon”) 效果： ![icon](https://gitee.com/tsund/data/raw/master/favicon/favicon-180x180.png \"icon\") 另：使用 &lt;center&gt;&lt;/center&gt; 嵌套使图片居中： \\ ![](url) \\&lt;/center> 5. 区块引用使用 &gt; 表示引用 > 区块引用>> 嵌套引用 效果： 区块引用 嵌套引用 6. 代码区块在每行加上 4 个空格或者一个制表符 public static void main(String args[]){&nbsp;&nbsp;&nbsp;&nbsp;System.out.println(“Hello World”);} 效果： public static void main(String args[]) { System.out.println(&quot;Hello World&quot;); } 注意：此时需要与普通段落之间存在空行 或者，使用```包裹代码（推荐），如下： ```javapublic static void main(String args[]) {&nbsp;&nbsp;&nbsp;&nbsp;System.out.println(“Hello World”); }``` 注意：```后面紧跟展示代码所使用的语言，如 java、javascript、python、shell 等 7. 目录Markdown 自动生成目录详见：https://blog.csdn.net/sculpta/article/details/104173014 8. 列表8.1 无序列表使用 · 、+ 、或 - 标记无序列表，可嵌套 - 第一项- 第二项- 第三项 效果： 第一项 第二项 第三项 8.2 有序列表有序列表的标记方式是序号后面加 . 1. 第一项2. 第二项3. 第三项 效果： 第一项 第二项 第三项 9. 复选框 - [ ] a- [x] b- [ ] c- [x] d 效果： [ ] a [x] b [ ] c [x] d 10. 表情 😏10.1 Emoji目前 Emoji 已经支持大部分文本输入场景，当然也适用于 Markdown😆 注意：Emoji 表情在不同设备、不同软件、不同浏览器显示会有所不同 随便附上几个（直接选中复制、粘贴就 OK），更多可以参考 Emoji All 😀 😃 😄 😁 😆 😅 😂 😋 😒 😏 🙃 🙂 😐 😑 ⭐ 🌟 ✨ 🔥 10.2 符号表情山顶洞人用的表情包 ʕ •ᴥ•ʔ ( ´◔ ‸◔`) ⊙▂⊙ ⊙ ０ ⊙ ⊙︿⊙ ⊙ω⊙ ⊙﹏⊙ ⊙△⊙ ⊙▽⊙ ∩▂∩ ∩ ０ ∩ ∩︿∩ ∩ω∩ ∩﹏∩ ∩△∩ ∩▽∩ ●▂● ● ０ ● ●︿● ●ω● ●﹏● ●△● ●▽● ∪▂∪ ∪ ０ ∪ ∪︿∪ ∪ω∪ ∪﹏∪ ∪△∪ ∪▽∪ ≧▂≦ ≧ ０ ≦ ≧︿≦ ≧ω≦ ≧﹏≦ ≧△≦ ≧▽≦ ＞ ▂ ＜ ＞０＜ ＞︿＜ ＞ ω ＜ ＞﹏＜ ＞ △ ＜ ＞ ▽ ＜ 参考链接： 标点符号表情大全 11. 分割线使用三个或以上 * 、 - 、 _ 效果： 12. 表格 😂用 | 表示表格纵向边界，表头和表内容用 - 隔开，并可用 : 进行对齐设置——两边都有 : 则表示居中，若不加 : 则默认左对齐 | 表头 | 内容 || :——: | :———————————: || Google | https://www.google.com || Baidu | https://www.baidu.com | 效果： 表头 内容 Google https://www.google.com Baidu https://www.baidu.com 13. 注脚 一个具有注脚的文本。[^1] [^1]: 注脚的解释 效果： 一个具有注脚的文本。1 1. 注脚的解释 ↩ 14. 折叠内容 \\\\Title（点击展开隐藏内容）\\ content \\&lt;/details&gt; 效果： Title（点击展开隐藏内容） content 注意：部分场景（如 CSDN）可能不支持该语法，不过在 vs code、github 等场景可以正常显示 15. 数学公式 😉 详细数学公式语法，链接：Markdown 语法之数学公式（from CSDN）","link":"/2020/02/02/markdown-usage/"},{"title":"C++ mmap 多进程文件读写","text":"mmap 采用内存映射的方式，直接将磁盘上的文件映射到内存（准确的说是虚拟内存）中，不需要其他额外空间，对内存映射区的修改可以与磁盘文件保持同步，故 mmap 的读写速度非常快 使用 mmap 需注意以下两点： 仅支持 linux 系统 mmap 映射区域大小必须是物理页大小（page size）的整倍数（32 位系统中通常是 4k 字节） 1. mmap 使用12345678#include &lt;sys/mman.h&gt;#include &lt;fcntl.h&gt;// 开启映射void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);// 关闭映射int munmap(void *start, size_t length); 函数形参含义： *start: 指向欲映射的内存起始地址，通常设为 NULL，表示让系统自动选定地址，映射成功后返回该地址 length: 表示将文件中多大的部分映射到内存，即映射区的长度 prot: 映射区域的保护方式，不能与文件的打开模式冲突。可以为以下一种或几种方式，多种方式使用 or 组合（”|“） PROT_EXEC: 映射区域可被执行 PROT_READ: 映射区域可被读取 PROT_WRITE: 映射区域可被写入 PROT_NONE: 映射区域不能存取 flags: 影响映射区域的各种特性，指定映射对象的类型，映射选项和映射页是否可以共享。在调用 mmap() 时必须要指定 MAP_SHARED 或 MAP_PRIVATE，flags 可以是以下一个或者多个值： MAP_FIXED: 如果参数 start 所指的地址无法成功建立映射时，则放弃映射，不对地址做修正。通常不鼓励这样设置 MAP_SHARED: 对映射区域的写入数据会复制回文件内，而且允许其他映射该文件的进程共享。与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到 msync() 或者 munmap() 被调用，文件实际上不会被更新 MAP_PRIVATE: 对映射区域的写入操作会产生一个映射文件的复制，即私人的“写入时复制”（copy on write）对此区域作的任何修改都不会写回原来的文件内容，写入不会影响到原文件。这个标志和 MAP_SHARED 是互斥的，只能使用其中之一 MAP_ANONYMOUS: 建立匿名映射。此时会忽略参数fd，不涉及文件，而且映射区域无法和其他进程共享。 MAP_DENYWRITE: 只允许对映射区域的写入操作，其他对文件直接写入的操作将会被拒绝 MAP_LOCKED: 将映射区域锁定住，这表示该区域不会被置换（swap），从而防止页面被交换出内存 MAP_NORESERVE: 不为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号 MAP_LOCKED: 锁定映射区的页面，从而防止页面被交换出内存 MAP_GROWSDOWN: 用于堆栈，告诉内核 VM 系统，映射区可以向下扩展 MAP_POPULATE: 为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞 MAP_NONBLOCK: 仅和 MAP_POPULATE 一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口 fd: 要映射到内存中的文件描述符 offset: 文件映射的偏移量，通常设置为 0，表示从文件起始位置对应，offset 必须是 page size 的整数倍 返回值： 若映射成功，mmap() 返回映射区的内存起始地址，munmap() 返回 0 若映射失败，mmap() 返回 MAP_FAILED，其值为(void *)-1，munmap() 返回 -1 2. mmap 读1234567891011int fd = open(file_name.c_str(), O_RDONLY);// 读取文件长度int len = lseek(fd, 0, SEEK_END);// 建立映射char *buffer = (char *) mmap(NULL, len, PROT_READ, MAP_PRIVATE, fd, 0);close(fd);// do something// 关闭映射munmap(buffer, len); 3. mmap 写123456789101112131415int len = data.length();// 打开文件int fd = open(file_name.c_str(), O_RDWR | O_CREAT, 00777);// lseek将文件指针往后移动 len - 1 位lseek(fd, len - 1, SEEK_END);// 预先写入一个空字符；mmap不能扩展文件长度，这里相当于预先给文件长度，准备一个空架子write(fd, &quot; &quot;, 1);// 建立映射char *buffer = (char *) mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);// 关闭文件close(fd);// 将 data 复制到 buffer 里memcpy(buffer, data, len);// 关闭映射munmap(buffer, len) 4. mmap 多进程写不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的 这里以 8 进程为例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;bits/stdc++.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;#include &lt;fcntl.h&gt;using namespace std;const int PROCESS_COUNT = 8;const int RESULT_SIZE = 20000;void work(const string &amp;file_name, int pid) { int fd = open(file_name.c_str(), O_RDWR | O_CREAT, 0666); char *buffer = (char *) mmap(NULL, RESULT_SIZE * 2, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); int start = pid * RESULT_SIZE / PROCESS_COUNT; int end = start + RESULT_SIZE / PROCESS_COUNT; for (int i = start; i &lt; end; ++i) { buffer[i &lt;&lt; 1] = (i % 2 != 0 ? '1' : '0'); buffer[i &lt;&lt; 1 | 1] = '\\n'; } munmap(buffer, RESULT_SIZE * 2);}int main() { string predict_file = &quot;result.txt&quot;; // 填充文件 int fd = open(predict_file.c_str(), O_RDWR | O_CREAT, 0666); lseek(fd, RESULT_SIZE * 2 - 1, SEEK_SET); write(fd, &quot; &quot;, 1); close(fd); // mmap多进程写 int id; pid_t pid; vector&lt;pid_t&gt; pids; for (int i = 1; i &lt; PROCESS_COUNT; i++) { id = i; pid = fork(); if (pid &lt;= 0) break; pids.push_back(pid); } if (pid == -1) { cerr &lt;&lt; &quot;startup process failed&quot; &lt;&lt; endl; } else { if (pid == 0) { work(predict_file, id); // 子进程 exit(0); } else { work(predict_file, 0); // main进程 } } exit(0);} 5. 注意事项mmap 映射区域大小必须是物理页大小（page size）的整倍数（32 位系统中通常是 4k 字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位，为了匹配内存的操作，mmap 从磁盘到虚拟地址空间的映射也必须是页 但是我们要读写的文件大小往往并不是 4k 的整数倍，因此在建立映射时一定要准确把握文件大小与映射区的 length 大小 若文件不是 4k 的整数倍，此时实际映射区域依然是 4k 的整数倍，剩余部分用 0 填充。尽管剩余部分不在文件范围内，但是依然可以正常读写，该部分内容的改变并不影响原文件。（比如文件大小为 8000 字节，则实际映射区域大小为 8192 字节，8000 ~ 8192 字节用 0 填充，并且该区域可以正常访问） 若设置映射区域大小远大于文件大小，比如文件大小 8000 字节，设置 length 为 100000 字节，则只有与文件相对应的物理页读写有效，即仅有前两页有效，对于 8192 ~ 100000 区域以及 100000 以外的区域，进程不能读写","link":"/2020/05/04/mmap/"},{"title":"Protege 使用教程","text":"Protégé 软件是斯坦福大学医学院生物信息研究中心基于 Java 语言开发的本体编辑和知识获取软件，或者说是本体开发工具，也是基于知识的编辑器，属于开放源代码软件。该软件主要用于语义网中本体的构建，是语义网中本体构建的核心开发工具 Protégé 提供了本体概念类、关系、属性和实例的构建，并且屏蔽了具体的本体描述语言，用户只需在概念层次上进行领域本体模型的构建 Protégé 官网：https://protege.stanford.edu，GitHub 地址：https://github.com/protegeproject 下载地址：官网下载 or 百度云盘（提取码：p2hy） 1. 界面 Protégé 功能非常强大，不过常用的一般只有 Classes、Object properties、Data properties 等几个功能 2. Classes这里的类与面向对象中的类是一个含义，是对现实生活中一类具有共同特征的事物的抽象，在本体论中就表明是一个本体 在 Classes 标签下声明类，所有的类都是 Thing 的子类 右键「Add subclass」可以创建子类，但这样创建比较麻烦，可以使用下面的方法快速创建类结构 通过缩进表示层次关系，prefix 和 suffix 分别表示前缀和后缀 点击 Continue 后，选项表示是否使同一层次的类不相交，即同一对象不会同属于多个类，比如一个食物不可能同时既是披萨又是配料 3. Object propertiesobject properties，即对象属性，它表示本体与本体间的关系，比如披萨与配料之间的关系：披萨有哪些配料（hasTopping），配料可以做哪些披萨（isToppingOf） 这些关系可以看做是一个映射，有定义域、值域，在 Protégé 中就是 Domains 和 Ranges，如 hasTopping 这个对象属性，披萨就是定义域（Domains），配料就是值域（Ranges），并且与 isToppingOf 是互为相反（Inverse of）的关系，即两者的定义域与值域相反 在对象属性中有以下特性（Characteristics）： Functional: 函数性，即每个输入值对应唯一输出值，允许多个输入值对应同一输出值，但不允许同一输入值对应多个输出值。以 hasFather 为例，已知 john 的 Father 是 Mike 和 Smith，可以看出它违反了函数性，所以经过推导，得出 Mike 和 Smith 是同一个人 Inverse functional: 反函数性，与函数性相反，允许同一输入值对应多个输出值，不允许多个输入值对应同一输出值。例如 isMotherOf，Linda 和 Sara 是 Amy 的母亲，可以推导出 Linda 和 Sara 是同一个人 Transitive: 传递性。以 hasAncestor 为例，已知 Matthew 的祖先是 Peter，Peter 的祖先是 William，可以推导出 William 也是 Matthew 的祖先 Symmetric: 对称性。以 hasSibling 为例，已知 Matthew 的兄弟是 Gemma，同时可以推导出 Gemma 也是 Matthew 的兄弟 Asymmetric: 反对称性，与对称性相反。以 hasChild 为例，已知 Jean 有一个叫 Matthew 的孩子，那么 Matthew 就不能是 Jean 的孩子 Reflexive: 自反性。以 knows 为例，已知 George 认识 Simon，那么也可以推导出 George 认识自己，Simon 也认识自己 Irreflexive: 反自反性，与自反性相反。以 isFatherOf 为例，已知 Alex 是 Bob 的父亲，那么 Alex 就不能是自己的父亲，同样 Bob 也不能是自己的父亲 4. Data propertiesData properties，即数据属性，用来描述本体的属性。如 People 这个本体可能有 age、sex、name 等属性 创建 Data properties 同样也可以一次输入多个属性，使用制表符表示层次关系 Data properties 同样可指定函数性，与 Object properties 相似，允许多个输入值对应同一输出值，但不允许同一输入值对应多个输出值 Domains 指定拥有该属性的本体，pepoleProperties 的 Domains 自然就是 People 了，Ranges 指定属性值的类型，如 float、string、datetime 等","link":"/2020/04/03/protege/"},{"title":"微信小程序：生成随机且不重复字符","text":"Thought第一步，产生一个随机 code 第二步，从数据库中查询这个 code 第三步，判断，若已存在则退回第一步，若不存在则返回这个 code 不难发现这是一个递归的过程，而跳出递归的条件就是中途出错或者已经找到不重复的 code。 Promise StylefileUtil.js 中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 产生一个不重复的code */function generateCode() { let promise = new Promise(function(resolve, reject) { let code = getRandomCode(); queryCode(code).then(res =&gt; { if (res[0]) { // 需要结束 resolve(res[1]); } else { // 重复，不能结束，进行递归 return generateCode(); } }); }); return promise;}/** * 产生四位数字+字母随机字符 */function getRandomCode() { let code = &quot;&quot;; const array = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']; for (let i = 0; i &lt; 4; i++) { let id = Math.round(Math.random() * 61); code += array[id]; } return code;}/** * 从云数据库中查询code */function queryCode(code) { let promise = new Promise(function(resolve, reject) { // result[0] 代表是否需要结束，true：需要结束，false：不需要结束 var result = [false, &quot;&quot;]; wx.cloud.callFunction({ name: &quot;query-code&quot;, data: { code: code }, success: res =&gt; { let data = res.result.data; if (data.length === 0) { // 查询成功，code未重复 result = [true, code]; } else { // 查询成功，code重复,则继续生成code并判断 result[0] = false; } }, fail: error =&gt; { // 查询失败 result[0] = true; }, complete: () =&gt; { resolve(result); } }); }); return promise;} Testdetail.js 中 123fileUtil.generateUrl(this.data.fileID).then(res =&gt; { console.log(res);});","link":"/2020/02/02/random-code/"},{"title":"GitHub 和 Docker Hub 中 README 常用的徽章","text":"README 文件通常用来让人快速了解项目，它应大体包括以下内容： 项目背景 安装 使用 Badge 相关项目（可选） 主要项目负责人 参与贡献方式 开源协议 除了必要的描述外，使用几个漂亮的 Badge（徽章）能让介绍看起来不那么枯燥，而且如果包含几个如 Travis CI、Coveralls 这样的徽章的话，更能体现自己的代码质量 Travis CI 同 GitHub Actions 一样，都是一种提供持续继承服务的工具，Travis 绑定 GitHub 项目后，每次 push 时都会自动根据配置文件拉取最新代码、构建环境、按照测试模块进行自动测试，这样就能及时发现问题并修复 目前 GitHub 疯狂推荐 GitHub Actions，确实非常好用。还是推荐使用 GitHub Actions，不过顺便拿个 Travis CI 的徽章也不错 Coveralls 可以生成自动测试报告，完成测试覆盖率的统计 以上两种工具都与 GitHub 深度集成，不过略显繁琐，下面介绍一些简单实用又好看并且能够拿过来就用的徽章，主要用到 shields.io，它专门提供简洁、易读的 SVG 格式的徽章，并且支持许多 web 页面和持续集成服务 GitHub README 常用徽章1. 格式1&lt;img src=&quot;https://img.shields.io/github/:type/:user/:repo.svg&quot;/&gt; 其中，:type 表示类型，比如 license（开源协议）、repo-size（仓库大小）等，:user 是你 GitHub 的用户名，:repo 是你的仓库名 2. 开源协议 1&lt;img src=&quot;https://img.shields.io/github/license/tensorflow/tensorflow.svg&quot;/&gt; 3. 仓库大小 1&lt;img src=&quot;https://img.shields.io/github/repo-size/tensorflow/tensorflow.svg&quot;/&gt; 4. 最后提交时间 1&lt;img src=&quot;https://img.shields.io/github/last-commit/tensorflow/tensorflow.svg&quot;/&gt; 5. 编程语言 这个功能需要自定义，自定义的格式如下 1&lt;img src=&quot;https://img.shields.io/badge/&lt;LABEL&gt;-&lt;MESSAGE&gt;-&lt;COLOR&gt;.svg&quot;/&gt; 各大常用语言的徽章如下（颜色以 GitHub 仓库上方显示 language-color 为例） 语言 颜色 徽章 java #B07219 python #3572A5 c #555555 c++ #F34B7D php #4F5D95 scala #C22D40 ruby #701516 html #E34C26 css #563D7C javascript #F1E05A vue #2C3E50 shell #89E051 go #00ADD8 dockerfile #384D54 Docker Hub README 常用徽章1. 自动化 1&lt;img src=&quot;https://img.shields.io/docker/automated/tsund/tianchi_docker_practice.svg&quot;/&gt; 2. star 1&lt;img src=&quot;https://img.shields.io/docker/stars/tsund/tianchi_docker_practice.svg&quot;/&gt; 3. pull 1&lt;img src=&quot;https://img.shields.io/docker/pulls/tsund/tianchi_docker_practice.svg&quot;/&gt; 4. image-size格式 1&lt;img src=&quot;https://img.shields.io/docker/image-size/:user/:repo/:tag&quot;/&gt; 5. version格式 1&lt;img src=&quot;https://img.shields.io/docker/image-size/:user/:repo/:tag&quot;/&gt; 更多有趣的徽章可以参考 shields.io","link":"/2020/03/16/readme-badge/"},{"title":"天池 Docker 练习场比赛攻略+代码","text":"本文将详细讲述天池 Docker 练习场的比赛流程，并贴出代码以供参考 1. 比赛内容题目： 输出 Hello world 计算 /tcdata/num_list.csv 中一列数字的总和 在 /tcdata/num_list.csv 文件中寻找最大的 10 个数，从大到小生成一个 List 输出结果格式： 12345{ &quot;Q1&quot;:&quot;Hello world&quot;, &quot;Q2&quot;:sum值, &quot;Q3&quot;:[top10_list] } 注意事项： 输出 Hello world 就是将 &quot;Hello world&quot; 直接写入 result.json 中就行 /tcdata/num_list.csv ：提交镜像后评分系统中会有这个文件，所以在编程时直接引用就好 2. 编写代码下面以阿里云 Centos 7 为例 创建文件夹 1mkdir -p /data/tianchi_docker_test &amp;&amp; cd /data/tianchi_docker_test 在 tianchi_docker_test 文件夹中创建文件 1touch Dockerfile hello_world.py result.json run.sh 赋予权限 1chmod 755 * Dockerfile 中，直接复制模版就行 123456789101112# Base Images## 从天池基础镜像构建FROM registry.cn-shanghai.aliyuncs.com/tcc-public/python:3## 把当前文件夹里的文件构建到镜像的根目录下ADD . /## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行）WORKDIR /## 镜像启动后统一执行 sh run.shCMD [&quot;sh&quot;, &quot;run.sh&quot;] hello-world.py 中 123456789101112131415161718192021222324252627282930# coding:utf-8import jsonimport csvfile_name = '/tcdata/num_list.csv'data = []# 第一题，直接写入 Hello worldresult = { &quot;Q1&quot;: &quot;Hello world&quot;, &quot;Q2&quot;: 0, &quot;Q3&quot;: []}# 第二题，求和with open(file_name, 'r', encoding='utf-8') as f: reader = csv.reader(f) for row in reader: data.append(int(row[0]))sum = sum(data)result['Q2'] = sum# 第三题result['Q3'] = sorted(data, reverse=True)[0:10]# 保存到 result.jsonwith open('result.json', 'w', encoding='utf-8') as f: json.dump(result, f) run.sh 中 1python hello-world.py 3. 构建镜像并推送登录阿里云容器镜像服务 1docker login --username=用户名@aliyun.com registry.cn-shanghai.aliyuncs.com 构建镜像（注意：后面有个 .，表示使用当前目录下的 Dockerfile 构建镜像） 1docker build -t registry.cn-shanghai.aliyuncs.com/命名空间/镜像名称:版本号 . 推送镜像 1docker push registry.cn-shanghai.aliyuncs.com/命名空间/镜像名称:版本号 提交结果，镜像路径中填写： 1registry.cn-shanghai.aliyuncs.com/命名空间/镜像名称:版本号 OK，good luck !","link":"/2020/02/20/tianchi-docker-practice/"},{"title":"SSH 免密登录（设置后仍需输入密码的原因及解决方法）","text":"1. 需求机器 A （客户端）使用 SSH 免密连接机器 B（服务端） 2. 客户端配置 进入用户目录的 .ssh 目录，生成公钥和私钥 1ssh-keygen -t rsa -C &quot;email@domain.com&quot; -f filename 其中，-C 设置注释文字，例如邮箱；-f 指定密钥文件存储文件名 将生成的公钥分发到服务端 方法一：使用 ssh-copy-id 命令，将公钥添加到服务端的 authorized_keys 文件中 1ssh-copy-id -i ~/.ssh/filename.pub user@host 其中，user 是要登录服务端的用户名，host 是服务端的 ip 或 domain 方法二：将公钥拷贝到服务端，使用 cat 命令追加到 authorized_keys 文件中 1cat filename.pub &gt;&gt; authorized_keys 配置 config 文件 注意：由于密钥认证时默认使用 ~/.ssh/id_rsa 文件作为私钥，因此还需额外配置。如果使用的公钥和私钥是默认名，即 id_rsa，则该步可跳过 在 ~/.ssh 目录下新建一个 config 文件 1touch config 编辑 config 文件 1vi config 写入以下内容 1234Host aliyunHostName ipUser rootIdentityFile ~/.ssh/filename 其中，Host 标识一个配置区段，每个配置区段是用 Host 来区分的，例如我这里使用 aliyun 作为一个配置区段HostName 指定远程主机名User 指定登录用户名IdentityFile 指定密钥认证使用的私钥文件路径此外，还可以使用 Port 指定远程主机端口号，默认 22 3. 测试在客户端尝试连接服务端 1ssh user@host 若无需输入密码即可登录，则配置成功 4. 设置无效的原因及解决方法4.1 原因 客户端私钥文件路径未配置或配置错误 服务端配置错误 权限错误 /etc/ssh/sshd_config 文件配置错误 4.2 解决方法 检查客户端 ~/.ssh/config 文件，配置方法如前所述 在服务端修改权限 123chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 配置 /etc/ssh/sshd_config 文件，修改以下内容，启用秘钥验证 1PubkeyAuthentication yes 修改后重启 sshd 服务 1service sshd restart","link":"/2020/08/20/ssh-problem/"},{"title":"在西安电子科技大学读研是一种什么样的体验","text":"开学半年了，趁着疫情（划水）期间简单做个反思和总结，记录一下这半年的感受 科研氛围谈到感受，在一瞬间首先想到的就是 geek 在校园里无时无刻不充斥着程序员的气息，旁边餐桌上的师兄弟谈论着实验室项目的细节，擦肩而过的行人在电话里向老师汇报着实验进展，睿思上的技术博客一篇又一篇，天池的广告牌在不停更换，秋招时企业的牌子占满了半条街 ··· 作为一个从双非考上的渣渣，在刚入学时就感受到鸭梨山大，周围大佬层出不穷，此起彼伏，着实难顶。不过说实话，如果你主观上渴望变强，在这种氛围中就如顺水推舟，不进也进了 尽管科研氛围非常浓厚，但是压力确实也不小，不论是周围大佬带来的心理压力，还是导师给予的各种“教导”，都让人心生退却，不过这可能是国内院校科研的通病吧，看到诸如南邮自焚事件、华科坠楼事件、武理爸爸事件这类新闻（默哀三分钟 :(），跟他们的遭遇比起来，咱这算啥啊，何况化解压力是每个人的必修课，未来的多灾生活必定困难重重，面前一时的这点小事又算得了什么 校园生活其实在西电的生活是多姿多彩的，灰色并不是主色调 西电老校区在西安市区，东南门外一个路口就是地铁，赛格之类的大商场也不远，旅游景点就更不用说了，十三朝古都嘛 老校区小但是该有的体育场也有，如果你看到一个大爷想把他赶走，记得细细瞅瞅，因为他可能只是个二十出头的程序员 校内虽然没有健身房，但是周边的健身房真不少，而且隔着也不远，不过听说大家都是防止猝死才去健身的（逃 除了这些，睿思上的瓜总会在考试周及时出现，成为大家茶余饭后的谈资，成功缓解一下大家紧张的复习（预习）气氛。还有相亲板块也不错，优质的学霸单身狗一抓一大把 最后，说到生活，不得不吐槽一下老校区的生活条件，**（此处省略一万字） 就业情况根据同学们或学长学姐描述的情况，就业的话去华为的比较多，去猫厂鹅厂的大佬也不少，按学校的统计数据，研究生平均薪资大概 1w~2w 吧 最后希望在新的学期中更加 geek 武汉加油！！","link":"/2020/02/08/xidian/"}],"tags":[{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Cloudflare","slug":"Cloudflare","link":"/tags/Cloudflare/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"路由器","slug":"路由器","link":"/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"Tools","slug":"Tools","link":"/tags/Tools/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Solutions","slug":"Solutions","link":"/tags/Solutions/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"GitHub Actions","slug":"GitHub-Actions","link":"/tags/GitHub-Actions/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Big Data","slug":"Big-Data","link":"/tags/Big-Data/"},{"name":"环境安装","slug":"环境安装","link":"/tags/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"知识图谱","slug":"知识图谱","link":"/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"小程序","slug":"小程序","link":"/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"Docker Hub","slug":"Docker-Hub","link":"/tags/Docker-Hub/"},{"name":"比赛","slug":"比赛","link":"/tags/%E6%AF%94%E8%B5%9B/"},{"name":"日记","slug":"日记","link":"/tags/%E6%97%A5%E8%AE%B0/"}],"categories":[{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"Cloudflare","slug":"Cloudflare","link":"/categories/Cloudflare/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"路由器","slug":"路由器","link":"/categories/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"GitHub","slug":"GitHub","link":"/categories/GitHub/"},{"name":"Big Data","slug":"Big-Data","link":"/categories/Big-Data/"},{"name":"知识图谱","slug":"知识图谱","link":"/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"Markdown","slug":"Markdown","link":"/categories/Markdown/"},{"name":"C++","slug":"C","link":"/categories/C/"},{"name":"小程序","slug":"小程序","link":"/categories/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"比赛","slug":"比赛","link":"/categories/%E6%AF%94%E8%B5%9B/"},{"name":"日记","slug":"日记","link":"/categories/%E6%97%A5%E8%AE%B0/"}],"pages":[{"title":"关于","text":"Hi, this is Ji Yuanhao.","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}